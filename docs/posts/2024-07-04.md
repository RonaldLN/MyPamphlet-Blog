---
draft: false
date: 2024-07-04
authors:
  - ronald_luo
categories:
  - Configure & Debug
comments: true
---

# é‡æ–°ç¼–å†™è§†è§‰æ¨¡å—è®°å½•

ç”±äºä»¥å‰çš„è§†è§‰éƒ¨åˆ†çš„ä»£ç çœ‹èµ·æ¥å¾ˆğŸ’©(æ„Ÿè§‰ä»£ç æ–‡ä»¶çš„ç»“æ„å¾ˆæ··ä¹±ï¼Œä¸å¤Ÿæ˜“è¯»)ï¼Œäºæ˜¯æ‰“ç®—é‡æ–°ç¼–å†™æ–°çš„ã€‚

æˆ‘å…ˆæ˜¯åˆ†åˆ«è¯¢é—®äº†chatgptå’Œcopilotå…³äºå¦‚ä½•åœ¨æ‘„åƒå¤´ä¸€ç›´ä¿æŒå¼€å¯çš„çŠ¶æ€ä¸‹ï¼Œåˆ‡æ¢ä½¿ç”¨ä¸åŒçš„åŠŸèƒ½

<!-- more -->

???+ example "å¯¹è¯è®°å½•"

    === "ChatGPT"
    
        User:
    
        i have a question, There is a competition where I need to keep the camera on all the time, but different stages require the use of the camera to complete different tasks. For example, the first stage requires gesture recognition, the second stage requires face pose estimation, and both stages also require object detection. I can implement all three functions mentioned above separately (meaning that i can only implement one function when camera turned on), but I would like to ask how to switch between using different functions while keeping the camera on? how should I organize my code?
    
        &nbsp;
    
        ChatGPT:
    
        To switch between different functions (gesture recognition, face pose estimation, and object detection) while keeping the camera on, you can use a modular approach in your code. Here's a general strategy:
    
        1.   **Initialize the Camera:**
             Set up the camera to capture frames continuously. 
    
        2.   **Create Functions for Each Task:**
             Write separate functions for gesture recognition, face pose estimation, and object detection.
    
        3.   **Control Flow to Switch Between Tasks:**
             Use a control mechanism (e.g., a state machine, a flag, or a command listener) to determine which function to call on each frame.
    
        4.   **Main Loop:**
             In the main loop, capture frames and call the appropriate function based on the current task.
    
        Here's a simplified example in Python using OpenCV and a basic state machine:
    
        ```python linenums="1"
        import cv2
    
        # Initialize the camera
        cap = cv2.VideoCapture(0)
    
        # Define the functions for each task
        def gesture_recognition(frame):
            # Implement gesture recognition here
            pass
    
        def face_pose_estimation(frame):
            # Implement face pose estimation here
            pass
    
        def object_detection(frame):
            # Implement object detection here
            pass
    
        # State to control which function to use
        current_task = "gesture_recognition"
    
        # Main loop
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
    
            if current_task == "gesture_recognition":
                gesture_recognition(frame)
            elif current_task == "face_pose_estimation":
                face_pose_estimation(frame)
            elif current_task == "object_detection":
                object_detection(frame)
    
            # Display the frame
            cv2.imshow('Frame', frame)
    
            # Check for user input to switch tasks
            key = cv2.waitKey(1) & 0xFF
            if key == ord('g'):
                current_task = "gesture_recognition"
            elif key == ord('f'):
                current_task = "face_pose_estimation"
            elif key == ord('o'):
                current_task = "object_detection"
            elif key == ord('q'):
                break
    
        # Release the camera and close windows
        cap.release()
        cv2.destroyAllWindows()
        ```
    
        <h3>Explanation:</h3>
    
        1.   **Initialize the Camera:**
             -   `cap = cv2.VideoCapture(0)` initializes the camera.
    
        2.   **Define Functions:**
             -   `gesture_recognition`, `face_pose_estimation`, and `object_detection` are placeholders for your actual implementation.
    
        3.   **Control Flow:**
             -   `current_task` is a variable that controls which function to call.
             -   User input (`cv2.waitKey`) switches between tasks.
    
        4.   **Main Loop:**
             -   Continuously captures frames.
             -   Calls the appropriate function based on the current task.
             -   Displays the frame and listens for user input to switch tasks.
    
        This approach ensures that the camera remains on and the system can switch between different tasks based on the control flow. You can modify the control mechanism to suit the specific requirements of your competition.
    
    === "Github Copilot"
    
        RonaldLN: 
    
        i have a question, There is a competition where I need to keep the camera on all the time, but different stages require the use of the camera to complete different tasks. For example, the first stage requires gesture recognition, the second stage requires face pose estimation, and both stages also require object detection. I can implement all three functions mentioned above separately (meaning that i can only implement one function when camera turned on), but I would like to ask how to switch between using different functions while keeping the camera on? how should I organize my code?
    
        &nbsp;
    
        GitHub Copilot: 
    
        è¦åœ¨ä¿æŒæ‘„åƒå¤´å¼€å¯çš„æƒ…å†µä¸‹åˆ‡æ¢ä¸åŒçš„åŠŸèƒ½ï¼ˆå¦‚æ‰‹åŠ¿è¯†åˆ«ã€é¢éƒ¨å§¿æ€ä¼°è®¡å’Œç‰©ä½“æ£€æµ‹ï¼‰ï¼Œä½ å¯ä»¥é‡‡ç”¨ä»¥ä¸‹æ­¥éª¤ç»„ç»‡ä½ çš„ä»£ç ï¼š
    
        1.   **åˆå§‹åŒ–æ‘„åƒå¤´**ï¼šé¦–å…ˆï¼Œåˆå§‹åŒ–æ‘„åƒå¤´ï¼Œç¡®ä¿å®ƒåœ¨æ•´ä¸ªåº”ç”¨ç¨‹åºä¸­ä¿æŒå¼€å¯çŠ¶æ€ã€‚
        2.   **å®šä¹‰åŠŸèƒ½æ¨¡å—**ï¼šä¸ºæ‰‹åŠ¿è¯†åˆ«ã€é¢éƒ¨å§¿æ€ä¼°è®¡å’Œç‰©ä½“æ£€æµ‹å„å®šä¹‰ä¸€ä¸ªå‡½æ•°æˆ–ç±»ã€‚è¿™æ ·å¯ä»¥åœ¨éœ€è¦æ—¶è°ƒç”¨ç›¸åº”çš„åŠŸèƒ½ã€‚
        3.   **åˆ›å»ºåŠŸèƒ½åˆ‡æ¢é€»è¾‘**ï¼šæ ¹æ®æ¯”èµ›çš„é˜¶æ®µæˆ–ç”¨æˆ·çš„è¾“å…¥ï¼Œå†³å®šä½•æ—¶åˆ‡æ¢åˆ°ä¸åŒçš„åŠŸèƒ½ã€‚è¿™å¯èƒ½æ¶‰åŠåˆ°ç›‘å¬æŸç§ä¿¡å·æˆ–æ£€æŸ¥æŸä¸ªæ¡ä»¶ã€‚
        4.   **å¾ªç¯æ•è·å¸§**ï¼šåœ¨ä¸€ä¸ªå¾ªç¯ä¸­ä¸æ–­ä»æ‘„åƒå¤´æ•è·å¸§ï¼Œå¹¶æ ¹æ®å½“å‰çš„åŠŸèƒ½éœ€æ±‚ï¼Œå°†æ•è·çš„å¸§ä¼ é€’ç»™ç›¸åº”çš„åŠŸèƒ½æ¨¡å—å¤„ç†ã€‚
        5.   **å¤„ç†ç»“æœ**ï¼šæ¯ä¸ªåŠŸèƒ½æ¨¡å—å¤„ç†å®Œå¸§ä¹‹åï¼Œæ ¹æ®éœ€è¦è¿›è¡Œç»“æœçš„æ˜¾ç¤ºã€å­˜å‚¨æˆ–è¿›ä¸€æ­¥å¤„ç†ã€‚
    
        ä»¥ä¸‹æ˜¯ä¸€ä¸ªç®€åŒ–çš„ä¼ªä»£ç ç¤ºä¾‹ï¼š
    
        ```python linenums="1"
        def init_camera():
            # åˆå§‹åŒ–æ‘„åƒå¤´
            pass
    
        def gesture_recognition(frame):
            # å¤„ç†å¸§è¿›è¡Œæ‰‹åŠ¿è¯†åˆ«
            pass
    
        def face_pose_estimation(frame):
            # å¤„ç†å¸§è¿›è¡Œé¢éƒ¨å§¿æ€ä¼°è®¡
            pass
    
        def object_detection(frame):
            # å¤„ç†å¸§è¿›è¡Œç‰©ä½“æ£€æµ‹
            pass
    
        def main():
            camera = init_camera()
            current_stage = 1  # å‡è®¾1ä¸ºæ‰‹åŠ¿è¯†åˆ«ï¼Œ2ä¸ºé¢éƒ¨å§¿æ€ä¼°è®¡ï¼Œ3ä¸ºç‰©ä½“æ£€æµ‹
    
            while True:
                frame = camera.capture_frame()
    
                if current_stage == 1:
                    gesture_recognition(frame)
                elif current_stage == 2:
                    face_pose_estimation(frame)
                elif current_stage == 3:
                    object_detection(frame)
    
                # æ ¹æ®æŸäº›æ¡ä»¶æ›´æ–°current_stageæ¥åˆ‡æ¢åŠŸèƒ½
                # ä¾‹å¦‚ï¼ŒåŸºäºç”¨æˆ·è¾“å…¥æˆ–æ—¶é—´é™åˆ¶
    
        if __name__ == "__main__":
            main()
        ```
    
        è¿™ä¸ªç»“æ„å…è®¸ä½ åœ¨ä¸å…³é—­æ‘„åƒå¤´çš„æƒ…å†µä¸‹ï¼Œæ ¹æ®æ¯”èµ›çš„ä¸åŒé˜¶æ®µæˆ–å…¶ä»–æ¡ä»¶ï¼Œçµæ´»åœ°åˆ‡æ¢ä¸åŒçš„å¤„ç†åŠŸèƒ½ã€‚

å‚è€ƒå®ƒä»¬ç»™å‡ºçš„å›ç­”ï¼Œæ‰“ç®—å°†æ¯ä¸ªåŠŸèƒ½å°è£…æˆä¸€ä¸ªå‡½æ•°æˆ–è€…ç±»ï¼Œåœ¨ä¸»å¾ªç¯ä¸­éœ€è¦å¼€å¯ä½¿ç”¨åŠŸèƒ½å°±æŠŠå½“å‰ä»æ‘„åƒå¤´è·å–åˆ°çš„å¸§ä¼ å…¥å…·ä½“çš„å‡½æ•°æˆ–è€…ç±»å³å¯ã€‚

---

å¹¶ä¸”æ‰“ç®—å€ŸåŠ©gitçš„submoduleåŠŸèƒ½ï¼Œè®©ä»£ç çœ‹çš„æ›´æ¸…æ™°ä¸”æ›´å®¹æ˜“ç»´æŠ¤

äºæ˜¯å…ˆåˆ›å»ºäº† `vision` çš„ä»“åº“å¹¶cloneï¼Œç„¶ååˆ›å»ºäº† `face_orientation_recognition` å’Œ `face_identification` ä¸¤ä¸ªä»“åº“ï¼Œå†åœ¨ `vision` ä¸­æ·»åŠ submodule

```bash
git submodule add face_orientation_recognition.git src/scripts/face_orientation_recognition
```

```bash
git submodule add face_identification.git src/scripts/face_identification
```

---

è€Œç”±äºä¸æ˜¯å¾ˆæ¸…æ¥špythonçš„åŒ…ä¸­çš„æ–‡ä»¶ç»“æ„è¦å¦‚ä½•ç»„ç»‡æ‰èƒ½æ¯”è¾ƒæ¸…æ™°ï¼Œæ‰€ä»¥è¯¢é—®äº†ä¸€ä¸‹chatgpt

??? example "å¯¹è¯è®°å½•"

    User:
    
    åœ¨pythonè‡ªå·±åˆ›å»ºçš„åŒ…ä¸­ï¼Œä¸€èˆ¬moduleså’Œutils çš„å­æ–‡ä»¶å¤¹ä¸­ï¼Œé€šå¸¸çš„å«ä¹‰å’Œç”¨é€”æ˜¯ä»€ä¹ˆï¼Ÿ
    
    &nbsp;
    
    ChatGPT:
    
    åœ¨PythonåŒ…ä¸­ï¼Œ`modules`å’Œ`utils`å­æ–‡ä»¶å¤¹é€šå¸¸æœ‰ç‰¹å®šçš„ç”¨é€”å’Œå«ä¹‰ï¼Œå°½ç®¡å®ƒä»¬çš„ç¡®åˆ‡ç”¨é€”å¯èƒ½ä¼šå› é¡¹ç›®è€Œå¼‚ã€‚ä»¥ä¸‹æ˜¯å®ƒä»¬çš„ä¸€äº›å¸¸è§ç”¨é€”ï¼š
    
    <h3>`modules` æ–‡ä»¶å¤¹</h3>
    
    1.   **æ ¸å¿ƒåŠŸèƒ½**ï¼š
         -   `modules` æ–‡ä»¶å¤¹é€šå¸¸åŒ…å«å®ç°è½¯ä»¶æˆ–åº“çš„æ ¸å¿ƒåŠŸèƒ½çš„æ¨¡å—ã€‚è¿™äº›æ¨¡å—å¯ä»¥æ˜¯ä¸åŒçš„ç»„ä»¶æˆ–åŠŸèƒ½å•å…ƒï¼Œå®ƒä»¬ä¸€èµ·ç»„æˆäº†æ•´ä¸ªè½¯ä»¶ç³»ç»Ÿã€‚
       
    2.   **åˆ†ç¦»å…³æ³¨ç‚¹**ï¼š
         -   æ¯ä¸ªæ¨¡å—å¯èƒ½ä¸“æ³¨äºç‰¹å®šçš„åŠŸèƒ½æˆ–ä»»åŠ¡ï¼Œä¾‹å¦‚æ•°æ®å¤„ç†ã€ç½‘ç»œé€šä¿¡ã€ç”¨æˆ·è®¤è¯ç­‰ã€‚è¿™ç§åˆ†ç¦»æœ‰åŠ©äºæé«˜ä»£ç çš„å¯ç»´æŠ¤æ€§å’Œå¯è¯»æ€§ã€‚
    
    3.   **å‘½åçº¦å®š**ï¼š
         -   è¿™ä¸ªæ–‡ä»¶å¤¹çš„åç§°â€œmodulesâ€å¹¶æ²¡æœ‰å¼ºåˆ¶æ€§çš„çº¦å®šï¼Œä½†å®ƒé€šå¸¸è¢«ç”¨æ¥è¡¨æ˜è¿™äº›æ–‡ä»¶æ˜¯ç¨‹åºçš„ä¸»è¦ç»„æˆéƒ¨åˆ†ã€‚
    
    <h3>`utils` æ–‡ä»¶å¤¹</h3>
    
    1.   **å®ç”¨å·¥å…·**ï¼š
         -   `utils` æ–‡ä»¶å¤¹é€šå¸¸åŒ…å«å„ç§å®ç”¨å·¥å…·å‡½æ•°æˆ–è¾…åŠ©å‡½æ•°ï¼Œè¿™äº›å‡½æ•°ä¸æ˜¯ç¨‹åºçš„æ ¸å¿ƒåŠŸèƒ½ï¼Œä½†åœ¨å¤šä¸ªåœ°æ–¹éƒ½å¯èƒ½ä¼šç”¨åˆ°ã€‚å®ƒä»¬é€šå¸¸æ˜¯ä¸€äº›é€šç”¨çš„ã€å¯ä»¥å¤ç”¨çš„ä»£ç ç‰‡æ®µã€‚
       
    2.   **ä»£ç å¤ç”¨**ï¼š
         -   å°†å¸¸ç”¨çš„è¾…åŠ©å‡½æ•°æ”¾åœ¨`utils`æ–‡ä»¶å¤¹ä¸­ï¼Œå¯ä»¥é¿å…ä»£ç é‡å¤ï¼Œæé«˜ä»£ç å¤ç”¨æ€§ã€‚ä¾‹å¦‚ï¼Œå­—ç¬¦ä¸²å¤„ç†ã€æ—¥æœŸå¤„ç†ã€æ–‡ä»¶æ“ä½œç­‰é€šç”¨åŠŸèƒ½é€šå¸¸ä¼šæ”¾åœ¨è¿™é‡Œã€‚
    
    3.   **ç»„ç»‡è¾…åŠ©ä»£ç **ï¼š
         -   è¿™ä¸ªæ–‡ä»¶å¤¹çš„å­˜åœ¨ä½¿å¾—ä¸»è¦æ¨¡å—çš„ä»£ç æ›´åŠ ç®€æ´ï¼Œå› ä¸ºè¾…åŠ©åŠŸèƒ½è¢«ç§»åˆ°äº†ä¸€ä¸ªç‹¬ç«‹çš„åœ°æ–¹ã€‚è¿™ä¹Ÿæœ‰åŠ©äºæ›´å¥½åœ°ç»„ç»‡ä»£ç ã€‚
    
    <h3>å…·ä½“ä¾‹å­</h3>
    
    å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªåä¸º`my_package`çš„åŒ…ï¼Œä¸‹é¢æ˜¯ä¸€ä¸ªå¯èƒ½çš„æ–‡ä»¶å¤¹ç»“æ„ï¼š
    
    ```txt
    my_package/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ modules/
    â”‚   â”œâ”€â”€ data_processing.py
    â”‚   â”œâ”€â”€ network.py
    â”‚   â””â”€â”€ authentication.py
    â””â”€â”€ utils/
        â”œâ”€â”€ string_utils.py
        â”œâ”€â”€ date_utils.py
        â””â”€â”€ file_utils.py
    ```
    
    -   `data_processing.py`ã€`network.py`å’Œ`authentication.py`å¯èƒ½åŒ…å«å¤„ç†æ•°æ®ã€ç½‘ç»œé€šä¿¡å’Œç”¨æˆ·è®¤è¯çš„æ ¸å¿ƒä»£ç ã€‚
    -   `string_utils.py`ã€`date_utils.py`å’Œ`file_utils.py`åŒ…å«å„ç§å­—ç¬¦ä¸²å¤„ç†ã€æ—¥æœŸå¤„ç†å’Œæ–‡ä»¶æ“ä½œçš„è¾…åŠ©å‡½æ•°ã€‚
    
    è¿™ç§ç»“æ„æœ‰åŠ©äºä»£ç çš„æ¨¡å—åŒ–å’Œç»„ç»‡ï¼Œä½¿å¾—é¡¹ç›®æ›´å®¹æ˜“ç»´æŠ¤å’Œæ‰©å±•ã€‚
    
    &nbsp;
    
    User:
    
    è¿˜æœ‰å“ªäº›å¸¸ç”¨å’Œå¸¸è§çš„å­æ–‡ä»¶å¤¹åå‘¢ï¼Ÿ
    
    &nbsp;
    
    ChatGPT:
    
    åœ¨Pythoné¡¹ç›®ä¸­ï¼Œè¿˜æœ‰ä¸€äº›å¸¸è§çš„å­æ–‡ä»¶å¤¹åç§°ï¼Œå®ƒä»¬é€šå¸¸ç”¨äºç‰¹å®šçš„ç”¨é€”æˆ–ç»„ç»‡ä»£ç ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›å¸¸è§çš„å­æ–‡ä»¶å¤¹åç§°åŠå…¶ç”¨é€”ï¼š
    
    <h3>å¸¸è§å­æ–‡ä»¶å¤¹åç§°åŠç”¨é€”</h3>
    
    1.   **`config`**ï¼š
         -   ç”¨äºå­˜æ”¾é…ç½®æ–‡ä»¶å’Œé…ç½®ç›¸å…³çš„ä»£ç ã€‚
         -   ä¾‹å¦‚ï¼Œæ•°æ®åº“é…ç½®ã€APIå¯†é’¥ã€åº”ç”¨ç¨‹åºè®¾ç½®ç­‰ã€‚
    
    2.   **`tests`**ï¼š
         -   ç”¨äºå­˜æ”¾å•å…ƒæµ‹è¯•ã€é›†æˆæµ‹è¯•å’Œå…¶ä»–ç±»å‹çš„æµ‹è¯•ä»£ç ã€‚
         -   é€šå¸¸åŒ…å«å„ç§æµ‹è¯•ç”¨ä¾‹æ¥ç¡®ä¿ä»£ç çš„æ­£ç¡®æ€§ã€‚
    
    3.   **`scripts`**ï¼š
         -   ç”¨äºå­˜æ”¾å„ç§è„šæœ¬æ–‡ä»¶ï¼Œè¿™äº›è„šæœ¬é€šå¸¸æ˜¯ç”¨æ¥æ‰§è¡Œä¸€äº›ç‰¹å®šä»»åŠ¡æˆ–æ“ä½œçš„ã€‚
         -   ä¾‹å¦‚ï¼Œæ•°æ®è¿ç§»è„šæœ¬ã€è‡ªåŠ¨åŒ–è„šæœ¬ç­‰ã€‚
    
    4.   **`docs`**ï¼š
         -   ç”¨äºå­˜æ”¾é¡¹ç›®çš„æ–‡æ¡£å’Œè¯´æ˜æ–‡ä»¶ã€‚
         -   ä¾‹å¦‚ï¼Œç”¨æˆ·æ‰‹å†Œã€APIæ–‡æ¡£ã€è®¾è®¡æ–‡æ¡£ç­‰ã€‚
    
    5.   **`examples`**ï¼š
         -   ç”¨äºå­˜æ”¾ç¤ºä¾‹ä»£ç å’Œç¤ºä¾‹åº”ç”¨ç¨‹åºã€‚
         -   å¸®åŠ©ç”¨æˆ·äº†è§£å¦‚ä½•ä½¿ç”¨åº“æˆ–æ¡†æ¶ã€‚
    
    6.   **`data`**ï¼š
         -   ç”¨äºå­˜æ”¾æ•°æ®æ–‡ä»¶ï¼Œä¾‹å¦‚CSVæ–‡ä»¶ã€JSONæ–‡ä»¶ã€æ•°æ®åº“æ–‡ä»¶ç­‰ã€‚
         -   å¸¸ç”¨äºæ•°æ®å¤„ç†å’Œæœºå™¨å­¦ä¹ é¡¹ç›®ã€‚
    
    7.   **`assets`**ï¼š
         -   ç”¨äºå­˜æ”¾é™æ€èµ„æºï¼Œä¾‹å¦‚å›¾ç‰‡ã€æ ·å¼è¡¨ã€JavaScriptæ–‡ä»¶ç­‰ã€‚
         -   å¸¸ç”¨äºWebé¡¹ç›®ã€‚
    
    8.   **`models`**ï¼š
         -   ç”¨äºå­˜æ”¾æ•°æ®æ¨¡å‹ç›¸å…³çš„ä»£ç ã€‚
         -   ä¾‹å¦‚ï¼ŒORMæ¨¡å‹ã€æœºå™¨å­¦ä¹ æ¨¡å‹ç­‰ã€‚
    
    9.   **`migrations`**ï¼š
         -   ç”¨äºå­˜æ”¾æ•°æ®åº“è¿ç§»æ–‡ä»¶ã€‚
         -   å¸¸ç”¨äºDjangoã€Flaskç­‰ä½¿ç”¨ORMçš„Webæ¡†æ¶ã€‚
    
    10.   **`lib`**ï¼š
          -   ç”¨äºå­˜æ”¾å¤–éƒ¨åº“æˆ–ä¾èµ–é¡¹ã€‚
          -   ä¾‹å¦‚ï¼Œè‡ªå®šä¹‰çš„ç¬¬ä¸‰æ–¹åº“æˆ–ä¾èµ–é¡¹ã€‚
    
    11.   **`bin`**ï¼š
          -   ç”¨äºå­˜æ”¾å¯æ‰§è¡Œæ–‡ä»¶å’Œè„šæœ¬ã€‚
          -   ä¾‹å¦‚ï¼Œå‘½ä»¤è¡Œå·¥å…·å’Œæ‰§è¡Œè„šæœ¬ã€‚
    
    <h3>ç¤ºä¾‹é¡¹ç›®ç»“æ„</h3>
    
    ä¸‹é¢æ˜¯ä¸€ä¸ªå‡è®¾çš„Pythoné¡¹ç›®ç»“æ„ç¤ºä¾‹ï¼š
    
    ```txt
    my_project/
    â”œâ”€â”€ config/
    â”‚   â”œâ”€â”€ settings.py
    â”‚   â””â”€â”€ secrets.py
    â”œâ”€â”€ data/
    â”‚   â”œâ”€â”€ input_data.csv
    â”‚   â””â”€â”€ processed_data.json
    â”œâ”€â”€ docs/
    â”‚   â”œâ”€â”€ README.md
    â”‚   â””â”€â”€ API.md
    â”œâ”€â”€ examples/
    â”‚   â”œâ”€â”€ example1.py
    â”‚   â””â”€â”€ example2.py
    â”œâ”€â”€ lib/
    â”‚   â””â”€â”€ custom_library.py
    â”œâ”€â”€ models/
    â”‚   â”œâ”€â”€ user_model.py
    â”‚   â””â”€â”€ product_model.py
    â”œâ”€â”€ modules/
    â”‚   â”œâ”€â”€ data_processing.py
    â”‚   â”œâ”€â”€ network.py
    â”‚   â””â”€â”€ authentication.py
    â”œâ”€â”€ scripts/
    â”‚   â”œâ”€â”€ migrate_data.py
    â”‚   â””â”€â”€ cleanup.py
    â”œâ”€â”€ tests/
    â”‚   â”œâ”€â”€ test_data_processing.py
    â”‚   â”œâ”€â”€ test_network.py
    â”‚   â””â”€â”€ test_authentication.py
    â””â”€â”€ utils/
        â”œâ”€â”€ string_utils.py
        â”œâ”€â”€ date_utils.py
        â””â”€â”€ file_utils.py
    ```
    
    è¿™ç§ç»“æ„æ¸…æ™°åœ°ç»„ç»‡äº†é¡¹ç›®çš„å„ä¸ªéƒ¨åˆ†ï¼Œä½¿å¾—é¡¹ç›®æ˜“äºå¯¼èˆªå’Œç»´æŠ¤ã€‚ä¸åŒçš„æ–‡ä»¶å¤¹æ ¹æ®å…¶ç”¨é€”åˆ†ç±»ï¼Œä½¿å¾—ä»£ç ç®¡ç†æ›´åŠ é«˜æ•ˆã€‚
    
    &nbsp;
    
    User:
    
    lib , models, modules, scripts, utils, config è¿™å‡ ä¸ªä¹‹é—´çš„åŒºåˆ«ï¼Œä½ èƒ½å†è¯¦ç»†è¯´ä¸€ä¸‹å—ï¼Ÿ
    
    &nbsp;
    
    ChatGPT:
    
    å½“ç„¶ï¼Œä»¥ä¸‹æ˜¯å¯¹ `lib`ã€`models`ã€`modules`ã€`scripts`ã€`utils` å’Œ `config` è¿™å‡ ä¸ªæ–‡ä»¶å¤¹ä¹‹é—´çš„è¯¦ç»†åŒºåˆ«å’Œç”¨é€”è§£é‡Šï¼š
    
    <h3>`lib`</h3>
    
    **ç”¨é€”**ï¼š
    -   ç”¨äºå­˜æ”¾å¤–éƒ¨åº“æˆ–è‡ªå®šä¹‰çš„åº“æ–‡ä»¶ã€‚è¿™äº›åº“æ–‡ä»¶å¯èƒ½æ˜¯ä»å¤–éƒ¨å¼•å…¥çš„ç¬¬ä¸‰æ–¹åº“ï¼Œä¹Ÿå¯èƒ½æ˜¯é¡¹ç›®ä¸­è‡ªå®šä¹‰çš„ã€å¯å¤ç”¨çš„ä»£ç æ¨¡å—ã€‚
    
    **å…¸å‹å†…å®¹**ï¼š
    -   ç¬¬ä¸‰æ–¹åº“çš„åŒ…è£…å™¨
    -   è‡ªå®šä¹‰çš„å·¥å…·åº“
    -   ä¸ä¾èµ–äºé¡¹ç›®å…·ä½“ä¸šåŠ¡é€»è¾‘çš„é€šç”¨åº“
    
    **ç¤ºä¾‹**ï¼š
    ```python
    lib/
    â”œâ”€â”€ custom_library.py
    â””â”€â”€ third_party_wrapper.py
    ```
    
    <h3>`models`</h3>
    
    **ç”¨é€”**ï¼š
    -   ç”¨äºå­˜æ”¾æ•°æ®æ¨¡å‹ç›¸å…³çš„ä»£ç ã€‚è¿™äº›æ¨¡å‹é€šå¸¸è¡¨ç¤ºé¡¹ç›®ä¸­ä½¿ç”¨çš„æ•°æ®ç»“æ„ï¼Œä¾‹å¦‚æ•°æ®åº“è¡¨ã€æœºå™¨å­¦ä¹ æ¨¡å‹ç­‰ã€‚
    
    **å…¸å‹å†…å®¹**ï¼š
    -   ORMï¼ˆå¯¹è±¡å…³ç³»æ˜ å°„ï¼‰æ¨¡å‹ï¼ˆå¦‚Djangoæˆ–SQLAlchemyçš„æ¨¡å‹ï¼‰
    -   æœºå™¨å­¦ä¹ æ¨¡å‹çš„å®šä¹‰å’Œè®­ç»ƒä»£ç 
    -   æ•°æ®ç»“æ„å®šä¹‰
    
    **ç¤ºä¾‹**ï¼š
    
    ```python
    models/
    â”œâ”€â”€ user_model.py
    â”œâ”€â”€ product_model.py
    â””â”€â”€ ml_model.py
    ```
    
    <h3>`modules`</h3>
    
    **ç”¨é€”**ï¼š
    -   ç”¨äºå­˜æ”¾å®ç°è½¯ä»¶æˆ–åº“çš„æ ¸å¿ƒåŠŸèƒ½çš„æ¨¡å—ã€‚è¿™äº›æ¨¡å—æ˜¯é¡¹ç›®çš„ä¸»è¦ç»„æˆéƒ¨åˆ†ï¼ŒåŒ…å«ä¸»è¦çš„ä¸šåŠ¡é€»è¾‘å’ŒåŠŸèƒ½å®ç°ã€‚
    
    **å…¸å‹å†…å®¹**ï¼š
    -   å„ç§åŠŸèƒ½æ¨¡å—ï¼Œå¦‚æ•°æ®å¤„ç†ã€ç½‘ç»œé€šä¿¡ã€ç”¨æˆ·è®¤è¯ç­‰
    -   æ¯ä¸ªæ¨¡å—é€šå¸¸ä¸“æ³¨äºç‰¹å®šçš„åŠŸèƒ½æˆ–ä»»åŠ¡
    
    **ç¤ºä¾‹**ï¼š
    
    ```python
    modules/
    â”œâ”€â”€ data_processing.py
    â”œâ”€â”€ network.py
    â””â”€â”€ authentication.py
    ```
    
    <h3>`scripts`</h3>
    
    **ç”¨é€”**ï¼š
    -   ç”¨äºå­˜æ”¾å„ç§è„šæœ¬æ–‡ä»¶ï¼Œè¿™äº›è„šæœ¬é€šå¸¸æ˜¯ç”¨æ¥æ‰§è¡Œç‰¹å®šä»»åŠ¡æˆ–æ“ä½œçš„ï¼Œä¾‹å¦‚æ•°æ®è¿ç§»ã€è‡ªåŠ¨åŒ–ä»»åŠ¡ç­‰ã€‚
    
    **å…¸å‹å†…å®¹**ï¼š
    -   æ•°æ®è¿ç§»è„šæœ¬
    -   è‡ªåŠ¨åŒ–è„šæœ¬
    -   å¯åŠ¨å’Œéƒ¨ç½²è„šæœ¬
    
    **ç¤ºä¾‹**ï¼š
    
    ```python
    scripts/
    â”œâ”€â”€ migrate_data.py
    â””â”€â”€ cleanup.py
    ```
    
    <h3>`utils`</h3>
    
    **ç”¨é€”**ï¼š
    -   ç”¨äºå­˜æ”¾å„ç§å®ç”¨å·¥å…·å‡½æ•°æˆ–è¾…åŠ©å‡½æ•°ï¼Œè¿™äº›å‡½æ•°ä¸æ˜¯é¡¹ç›®çš„æ ¸å¿ƒåŠŸèƒ½ï¼Œä½†åœ¨å¤šä¸ªåœ°æ–¹éƒ½å¯èƒ½ä¼šç”¨åˆ°ï¼Œæä¾›è¾…åŠ©æ”¯æŒã€‚
    
    **å…¸å‹å†…å®¹**ï¼š
    -   é€šç”¨çš„å·¥å…·å‡½æ•°ï¼Œä¾‹å¦‚å­—ç¬¦ä¸²å¤„ç†ã€æ—¥æœŸå¤„ç†ã€æ–‡ä»¶æ“ä½œç­‰
    -   å¯ä»¥è¢«å¤šä¸ªæ¨¡å—å¤ç”¨çš„ä»£ç 
    
    **ç¤ºä¾‹**ï¼š
    
    ```python
    utils/
    â”œâ”€â”€ string_utils.py
    â”œâ”€â”€ date_utils.py
    â””â”€â”€ file_utils.py
    ```
    
    <h3>`config`</h3>
    
    **ç”¨é€”**ï¼š
    -   ç”¨äºå­˜æ”¾é…ç½®æ–‡ä»¶å’Œé…ç½®ç›¸å…³çš„ä»£ç ã€‚è¿™äº›é…ç½®æ–‡ä»¶é€šå¸¸åŒ…å«é¡¹ç›®çš„å„ç§è®¾ç½®å’Œå‚æ•°ï¼Œä¾‹å¦‚æ•°æ®åº“é…ç½®ã€APIå¯†é’¥ç­‰ã€‚
    
    **å…¸å‹å†…å®¹**ï¼š
    -   åº”ç”¨ç¨‹åºè®¾ç½®
    -   ç¯å¢ƒå˜é‡é…ç½®
    -   å®‰å…¨å’Œæ•æ„Ÿä¿¡æ¯ï¼ˆé€šå¸¸éœ€è¦å®‰å…¨ç®¡ç†ï¼‰
    
    **ç¤ºä¾‹**ï¼š
    
    ```python
    config/
    â”œâ”€â”€ settings.py
    â””â”€â”€ secrets.py
    ```
    
    <h3>æ€»ç»“å¯¹æ¯”</h3>
    
    -   **`lib`**ï¼šå¤–éƒ¨æˆ–è‡ªå®šä¹‰çš„åº“æ–‡ä»¶ï¼Œä¸ç‰¹å®šäºé¡¹ç›®çš„ä¸šåŠ¡é€»è¾‘ã€‚
    -   **`models`**ï¼šæ•°æ®æ¨¡å‹å®šä¹‰å’Œç›¸å…³ä»£ç ï¼Œè¡¨ç¤ºé¡¹ç›®ä¸­çš„æ•°æ®ç»“æ„ã€‚
    -   **`modules`**ï¼šæ ¸å¿ƒåŠŸèƒ½æ¨¡å—ï¼ŒåŒ…å«ä¸»è¦ä¸šåŠ¡é€»è¾‘ã€‚
    -   **`scripts`**ï¼šæ‰§è¡Œç‰¹å®šä»»åŠ¡æˆ–æ“ä½œçš„è„šæœ¬æ–‡ä»¶ã€‚
    -   **`utils`**ï¼šé€šç”¨å·¥å…·å‡½æ•°å’Œè¾…åŠ©å‡½æ•°ï¼Œæä¾›æ”¯æŒå’Œå¤ç”¨ã€‚
    -   **`config`**ï¼šé…ç½®æ–‡ä»¶å’Œç›¸å…³ä»£ç ï¼Œç®¡ç†é¡¹ç›®è®¾ç½®å’Œå‚æ•°ã€‚
    
    è¿™ç§åˆ†ç±»å’Œç»„ç»‡æ–¹å¼æœ‰åŠ©äºä¿æŒé¡¹ç›®ç»“æ„æ¸…æ™°ï¼Œä¾¿äºç»´æŠ¤å’Œæ‰©å±•ã€‚

---

## ç¼–å†™ `face_orientation_recognition`

äºæ˜¯å°† `head-pose-estimation` ä¸­çš„ `face_detection.py` `mark_detection.py` `pose_estimation.py` ç§»åŠ¨åˆ° `face_orientation_recognition/modules/` ä¸‹ï¼Œ`utils.py` `assets/` ç§»åŠ¨åˆ° `face_orientation_recognition/` ä¸‹

å‚ç…§ `main.py` ï¼Œåœ¨ `face_orientation_recognition/` ä¸‹ç¼–å†™ `orientation_recognition.py`

```python title="orientation_recognition.py"
import cv2
import numpy as np

from modules.face_detection import FaceDetector
from modules.mark_detection import MarkDetector
from modules.pose_estimation import PoseEstimator
from utils import refine


class OrientationRecognizer:
    def __init__(self, frame_width, frame_height):
        ...

    def __call__(self, frame):
        ...


def get_orientation_angle(pose):
    ...

def get_adjustment(angle):
    ...
```

ç„¶ååœ¨ `vision/` ä¸‹æµ‹è¯•ä½¿ç”¨è¿™ä¸ªåŒ…

```python title="vision/test.py" linenums="1"
import cv2
from face_orientation_recognition.face_orientation import OrientationRecognizer

cap = cv2.VideoCapture(0)

frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

estimator = OrientationRecognizer(frame_width, frame_height)

while True:
    ret, frame = cap.read()
    if not ret:
        break

    has_face, estimated_frame, angle, adjustment = estimator(frame)

    if has_face:
        cv2.imshow('frame', estimated_frame)
        print(f'angle: {angle}, adjustment: {adjustment}')
    else:
        cv2.imshow('frame', frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break
```

å‡ºç°äº†æŠ¥é”™

```bash
Traceback (most recent call last):
  File "c:\Github\vision\src\scripts\test.py", line 2, in <module>
    from face_orientation_recognition.face_orientation import OrientationRecognizer
  File "c:\Github\vision\src\scripts\face_orientation_recognition\face_orientation.py", line 10, in <module>
    from modules.face_detection import FaceDetector
ModuleNotFoundError: No module named 'modules'
```

å‘ç°æ˜¯éœ€è¦ä½¿ç”¨**ç›¸å¯¹å¯¼å…¥**

>   æˆ‘å‚è€ƒäº†yolov8ä¸­çš„ä»£ç 
>
>   [ultralytics/ultralytics/trackers/byte_tracker.py at 5d479c73c2933fa5020632e1b2d5b77220dce156 Â· ultralytics/ultralytics (github.com)](https://github.com/ultralytics/ultralytics/blob/5d479c73c2933fa5020632e1b2d5b77220dce156/ultralytics/trackers/byte_tracker.py)
>
>   ```python title="byte_tracker.py"
>   # Ultralytics YOLO ğŸš€, AGPL-3.0 license
>   
>   import numpy as np
>   
>   from ..utils import LOGGER
>   from ..utils.ops import xywh2ltwh
>   from .basetrack import BaseTrack, TrackState
>   from .utils import matching
>   from .utils.kalman_filter import KalmanFilterXYAH
>   ```

å°† `face_orientation.py` ä¿®æ”¹æˆç›¸å¯¹å¯¼å…¥

```python hl_lines="4-7"
import cv2
import numpy as np

from .modules.face_detection import FaceDetector
from .modules.mark_detection import MarkDetector
from .modules.pose_estimation import PoseEstimator
from .utils import refine
```

å†æ¬¡è¿è¡Œï¼Œå‡ºç°äº†å¯¼å…¥æ¨¡å‹æ–‡ä»¶çš„æŠ¥é”™

```bash
Traceback (most recent call last):
  File "c:\Github\vision\src\scripts\test.py", line 9, in <module>  
    estimator = OrientationRecognizer(frame_width, frame_height)    
  File "c:\Github\vision\src\scripts\face_orientation_recognition\face_orientation.py", line 35, in __init__
    self.face_detector = FaceDetector("assets/face_detector.onnx")  
  File "c:\Github\vision\src\scripts\face_orientation_recognition\modules\face_detection.py", line 67, in __init__
    assert os.path.exists(model_file), f"File not found: {model_file}"
AssertionError: File not found: assets/face_detector.onnx
```

äºæ˜¯è¯¢é—®copilot

???+ example "å¯¹è¯è®°å½•"

    RonaldLN:
    
    `@terminal` `/explain` `#terminalLastCommand`
    
    &nbsp;
    
    Github Copilot:
    
    æ ¹æ®æ‚¨æä¾›çš„ç»ˆç«¯æœ€åè¿è¡Œå‘½ä»¤çš„ä¸Šä¸‹æ–‡ï¼Œé”™è¯¯ä¿¡æ¯è¡¨æ˜åœ¨åˆå§‹åŒ– `OrientationRecognizer` å¯¹è±¡æ—¶ï¼Œå°è¯•åŠ è½½ `face_detector.onnx` æ¨¡å‹æ–‡ä»¶å¤±è´¥ï¼Œå› ä¸ºæ— æ³•åœ¨æŒ‡å®šçš„è·¯å¾„ `assets/face_detector.onnx` æ‰¾åˆ°è¯¥æ–‡ä»¶ã€‚
    
    è¿™ä¸ªé—®é¢˜é€šå¸¸æ˜¯å› ä¸ºæ–‡ä»¶è·¯å¾„ä¸æ­£ç¡®æˆ–è€…æ–‡ä»¶ç¡®å®ä¸å­˜åœ¨äºé¢„æœŸçš„ä½ç½®ã€‚è§£å†³è¿™ä¸ªé—®é¢˜çš„æ–¹æ³•åŒ…æ‹¬ï¼š
    
    1.   **æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨**ï¼šé¦–å…ˆï¼Œç¡®ä¿ `face_detector.onnx` æ–‡ä»¶ç¡®å®å­˜åœ¨äºé¡¹ç›®çš„ `assets` ç›®å½•ä¸‹ã€‚ä½ éœ€è¦åœ¨ `C:\Github\vision` ç›®å½•ä¸‹æŸ¥æ‰¾ `assets` ç›®å½•ï¼Œå¹¶ç¡®è®¤ `face_detector.onnx` æ–‡ä»¶æ˜¯å¦åœ¨é‚£é‡Œã€‚
    
    2.   **æ­£ç¡®è®¾ç½®æ–‡ä»¶è·¯å¾„**ï¼šå¦‚æœ `assets` ç›®å½•å’Œ `face_detector.onnx` æ–‡ä»¶éƒ½å­˜åœ¨ï¼Œä½†ä»ç„¶å‡ºç°é”™è¯¯ï¼Œå¯èƒ½æ˜¯å› ä¸ºç¨‹åºè¿è¡Œæ—¶çš„å½“å‰å·¥ä½œç›®å½•ï¼ˆCWDï¼‰ä¸æ˜¯ä½ é¢„æœŸçš„ç›®å½•ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä½ å¯ä»¥ä½¿ç”¨ç»å¯¹è·¯å¾„æˆ–è€…ç›¸å¯¹äºå½“å‰è„šæœ¬æ–‡ä»¶çš„è·¯å¾„æ¥å¼•ç”¨æ¨¡å‹æ–‡ä»¶ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ çš„è„šæœ¬ä½äº `c:\Github\vision\src\scripts` ç›®å½•ä¸‹ï¼Œä½ å¯ä»¥è¿™æ ·ä¿®æ”¹ä»£ç ï¼š
    
         ```python
         import os
    
         # è·å–å½“å‰è„šæœ¬æ–‡ä»¶çš„ç›®å½•
         current_dir = os.path.dirname(os.path.abspath(__file__))
         # æ„å»ºæ¨¡å‹æ–‡ä»¶çš„ç»å¯¹è·¯å¾„
         model_path = os.path.join(current_dir, "..", "..", "assets", "face_detector.onnx")
    
         self.face_detector = FaceDetector(model_path)
         ```
    
         è¿™æ®µä»£ç ä½¿ç”¨ `os.path` æ¨¡å—æ¥æ„å»º `face_detector.onnx` æ–‡ä»¶çš„ç»å¯¹è·¯å¾„ï¼Œæ— è®ºå½“å‰çš„å·¥ä½œç›®å½•æ˜¯ä»€ä¹ˆï¼Œéƒ½èƒ½æ­£ç¡®åœ°æ‰¾åˆ°æ–‡ä»¶ã€‚
    
    3.   **ç¡®ä¿è·¯å¾„åˆ†éš”ç¬¦æ­£ç¡®**ï¼šåœ¨ Windows ç³»ç»Ÿä¸Šï¼Œè·¯å¾„åˆ†éš”ç¬¦æ˜¯åæ–œæ  `\`ï¼Œè€Œåœ¨ UNIX-like ç³»ç»Ÿä¸Šï¼ˆåŒ…æ‹¬ Linux å’Œ macOSï¼‰ï¼Œè·¯å¾„åˆ†éš”ç¬¦æ˜¯æ­£æ–œæ  `/`ã€‚è™½ç„¶ Python é€šå¸¸å¯ä»¥æ­£ç¡®å¤„ç†è¿™äº›å·®å¼‚ï¼Œä½†åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„è·¯å¾„åˆ†éš”ç¬¦å¯èƒ½ä¼šé¿å…è·¯å¾„é—®é¢˜ã€‚`os.path.join` æ–¹æ³•å¯ä»¥è‡ªåŠ¨å¤„ç†è¿™ç§å·®å¼‚ï¼Œæ‰€ä»¥æ¨èä½¿ç”¨ã€‚
    
    é€šè¿‡ä¸Šè¿°æ–¹æ³•ä¹‹ä¸€ï¼Œä½ åº”è¯¥èƒ½å¤Ÿè§£å†³æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶çš„é—®é¢˜ã€‚

äºæ˜¯è¿›è¡Œä¿®æ”¹

```python title="face_orientation.py" hl_lines="1 6-7 10 13"
import os
...
class OrientationRecognizer:
    def __init__(self, frame_width, frame_height):
        ...
        # è·å–å½“å‰è„šæœ¬æ–‡ä»¶çš„ç›®å½•
        current_dir = os.path.dirname(os.path.abspath(__file__))

        # Setup a face detector to detect human faces.
        self.face_detector = FaceDetector(os.path.join(current_dir, "assets", "face_detector.onnx"))

        # Setup a mark detector to detect landmarks.
        self.mark_detector = MarkDetector(os.path.join(current_dir, "assets", "face_landmarks.onnx"))
        ...
```

```python title="modules/pose_estimation.py" hl_lines="1-7 13"
import os


# è·å–å½“å‰è„šæœ¬æ–‡ä»¶çš„ç›®å½•
current_dir = os.path.dirname(os.path.abspath(__file__))
# æ¨¡å‹æ–‡ä»¶çš„ç»å¯¹è·¯å¾„
model_path = os.path.join(current_dir, "..", "assets", "model.txt")

...

class PoseEstimator:
    ...
    def _get_full_model_points(self, filename=model_path):
        ...
```

å†æ¬¡è¿è¡Œï¼Œå°±èƒ½å¤Ÿä½¿ç”¨æ‘„åƒå¤´è¿›è¡Œæ£€æµ‹äº†

---

ç„¶åç»§ç»­å†™ `face_identification` ï¼Œæœ‰äº† `face_orientation_recognition` çš„ç»éªŒï¼Œè¿™ä¸ªå°±ç®€å•å¾ˆå¤šäº†ï¼Œå¾ˆå¿«å°±å¼„å®Œäº†

