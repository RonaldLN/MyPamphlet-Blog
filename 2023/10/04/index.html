<!doctype html><html class=no-js lang=zh><meta charset=utf-8><meta content="width=device-width,initial-scale=1" name=viewport><link href=../03/exifquicktime/ rel=prev><link href=../08/neural-collaborative-filteringhttpspaperswithcodecompaperneural-collaborative-filtering/ rel=next><link href=../../../icons/favicon.png rel=icon><meta content="mkdocs-1.5.3, mkdocs-material-9.4.6" name=generator><title>复现代码过程记录 - My Pamphlet Blog</title><link href=../../../assets/stylesheets/main.35e1ed30.min.css rel=stylesheet><link href=../../../assets/stylesheets/palette.356b1318.min.css rel=stylesheet><link crossorigin href=https://fonts.gstatic.com rel=preconnect><link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback" rel=stylesheet><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link href=../../../css/timeago.css rel=stylesheet><link href=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/katex.min.css rel=stylesheet><link href=https://cdn.jsdelivr.net/npm/lxgw-wenkai-screen-web/style.css rel=stylesheet><link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC&display=swap" rel=stylesheet><link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono&display=swap" rel=stylesheet><link href=../../../stylesheets/my_scheme.css rel=stylesheet><link href=../../../stylesheets/custom.css rel=stylesheet><link href=../../../stylesheets/card.css rel=stylesheet><script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function n(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],n("js",new Date),n("config","G-H7SV12D750"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&n("event","search",{search_term:this.value})}),document$.subscribe(function(){var a=document.forms.feedback;if(void 0!==a)for(var e of a.querySelectorAll("[type=submit]"))e.addEventListener("click",function(e){e.preventDefault();var t=document.location.pathname,e=this.getAttribute("data-md-value");n("event","feedback",{page:t,data:e}),a.firstElementChild.disabled=!0;e=a.querySelector(".md-feedback__note [data-md-value='"+e+"']");e&&(e.hidden=!1)}),a.hidden=!1}),location$.subscribe(function(e){n("config","G-H7SV12D750",{page_path:e.pathname})})});var e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=G-H7SV12D750",document.getElementById("__analytics").insertAdjacentElement("afterEnd",e)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script><script>var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?7a9cfe470ed52fa0c0940a58fede385c";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();</script><link href=../../../assets/stylesheets/glightbox.min.css rel=stylesheet><style>html.glightbox-open{overflow:initial;height:100%}.gslide-title{user-select:text;margin-top:0}.gslide-desc{color:#666;user-select:text}.gslide-image img{background:#fff}.gscrollbar-fixer{padding-right:15px}.gdesc-inner{font-size:.75rem}body[data-md-color-scheme=slate] .gdesc-inner{background:var(--md-default-bg-color)}body[data-md-color-scheme=slate] .gslide-title,body[data-md-color-scheme=slate] .gslide-desc{color:var(--md-default-fg-color)}</style><script src=../../../assets/javascripts/glightbox.min.js></script><body data-md-color-accent=indigo data-md-color-primary=indigo data-md-color-scheme=sunset-glow dir=ltr><script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script><input autocomplete=off class=md-toggle data-md-toggle=drawer id=__drawer type=checkbox><input autocomplete=off class=md-toggle data-md-toggle=search id=__search type=checkbox><label class=md-overlay for=__drawer></label><div data-md-component=skip><a class=md-skip href=#_1> 跳转至 </a></div><div data-md-component=announce></div><header class=md-header data-md-component=header><nav class="md-header__inner md-grid" aria-label=页眉><a aria-label="My Pamphlet Blog" class="md-header__button md-logo" title="My Pamphlet Blog" data-md-component=logo href=../../..> <svg viewbox="0 0 448 512" xmlns=http://www.w3.org/2000/svg><path d="M96 0C43 0 0 43 0 96v320c0 53 43 96 96 96h320c17.7 0 32-14.3 32-32s-14.3-32-32-32v-64c17.7 0 32-14.3 32-32V32c0-17.7-14.3-32-32-32H96zm0 384h256v64H96c-17.7 0-32-14.3-32-32s14.3-32 32-32zm32-240c0-8.8 7.2-16 16-16h192c8.8 0 16 7.2 16 16s-7.2 16-16 16H144c-8.8 0-16-7.2-16-16zm16 48h192c8.8 0 16 7.2 16 16s-7.2 16-16 16H144c-8.8 0-16-7.2-16-16s7.2-16 16-16z"/></svg> </a><label class="md-header__button md-icon" for=__drawer><svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg></label><div class=md-header__title data-md-component=header-title><div class=md-header__ellipsis><div class=md-header__topic><span class=md-ellipsis> My Pamphlet Blog </span></div><div class=md-header__topic data-md-component=header-topic><span class=md-ellipsis> 复现代码过程记录 </span></div></div></div><form class=md-header__option data-md-component=palette><input aria-label="Switch to dark mode" data-md-color-media="(prefers-color-scheme: light)" class=md-option data-md-color-accent=indigo data-md-color-primary=indigo data-md-color-scheme=sunset-glow id=__palette_1 name=__palette type=radio><label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_2 hidden><svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg></label><input aria-label="Switch to light mode" data-md-color-media="(prefers-color-scheme: dark)" class=md-option data-md-color-accent=indigo data-md-color-primary=indigo data-md-color-scheme=sunset-glow-dark id=__palette_2 name=__palette type=radio><label class="md-header__button md-icon" title="Switch to light mode" for=__palette_1 hidden><svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg></label></form><label class="md-header__button md-icon" for=__search><svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg></label><div class=md-search data-md-component=search role=dialog><label class=md-search__overlay for=__search></label><div class=md-search__inner role=search><form class=md-search__form name=search><input aria-label=搜索 autocapitalize=off autocomplete=off autocorrect=off class=md-search__input data-md-component=search-query name=query placeholder=搜索 required spellcheck=false type=text><label class="md-search__icon md-icon" for=__search><svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg></label><nav aria-label=查找 class=md-search__options><a class="md-search__icon md-icon" aria-label=分享 data-clipboard data-clipboard-text data-md-component=search-share href=javascript:void(0) tabindex=-1 title=分享> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg> </a><button class="md-search__icon md-icon" aria-label=清空当前内容 tabindex=-1 title=清空当前内容 type=reset><svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg></button></nav><div class=md-search__suggest data-md-component=search-suggest></div></form><div class=md-search__output><div class=md-search__scrollwrap data-md-scrollfix><div class=md-search-result data-md-component=search-result><div class=md-search-result__meta>正在初始化搜索引擎</div><ol class=md-search-result__list role=presentation></ol></div></div></div></div></div><div class=md-header__source><a class=md-source data-md-component=source href=https://github.com/RonaldLN/MyPamphlet-Blog title=前往仓库> <div class="md-source__icon md-icon"><svg viewbox="0 0 448 512" xmlns=http://www.w3.org/2000/svg><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg></div> <div class=md-source__repository>RonaldLN/MyPamphlet-Blog</div> </a></div></nav></header><div class=md-container data-md-component=container><nav aria-label=标签 class=md-tabs data-md-component=tabs><div class=md-grid><ul class=md-tabs__list><li class="md-tabs__item md-tabs__item--active"><a class=md-tabs__link href=../../..> Blog </a></ul></div></nav><main class=md-main data-md-component=main><div class="md-main__inner md-grid"><div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation hidden><div class=md-sidebar__scrollwrap><div class=md-sidebar__inner><nav class="md-nav md-nav--primary md-nav--lifted" aria-label=导航栏 data-md-level=0><label class=md-nav__title for=__drawer><a aria-label="My Pamphlet Blog" class="md-nav__button md-logo" title="My Pamphlet Blog" data-md-component=logo href=../../..> <svg viewbox="0 0 448 512" xmlns=http://www.w3.org/2000/svg><path d="M96 0C43 0 0 43 0 96v320c0 53 43 96 96 96h320c17.7 0 32-14.3 32-32s-14.3-32-32-32v-64c17.7 0 32-14.3 32-32V32c0-17.7-14.3-32-32-32H96zm0 384h256v64H96c-17.7 0-32-14.3-32-32s14.3-32 32-32zm32-240c0-8.8 7.2-16 16-16h192c8.8 0 16 7.2 16 16s-7.2 16-16 16H144c-8.8 0-16-7.2-16-16zm16 48h192c8.8 0 16 7.2 16 16s-7.2 16-16 16H144c-8.8 0-16-7.2-16-16s7.2-16 16-16z"/></svg> </a> My Pamphlet Blog</label><div class=md-nav__source><a class=md-source data-md-component=source href=https://github.com/RonaldLN/MyPamphlet-Blog title=前往仓库> <div class="md-source__icon md-icon"><svg viewbox="0 0 448 512" xmlns=http://www.w3.org/2000/svg><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg></div> <div class=md-source__repository>RonaldLN/MyPamphlet-Blog</div> </a></div><ul class=md-nav__list data-md-scrollfix><li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"><input class="md-nav__toggle md-toggle" checked id=__nav_1 type=checkbox> <label class=md-nav__link for=__nav_1 id=__nav_1_label><span class=md-ellipsis> Blog </span> <span class="md-nav__icon md-icon"></span></label> <nav aria-expanded=true aria-labelledby=__nav_1_label class=md-nav data-md-level=1><label class=md-nav__title for=__nav_1><span class="md-nav__icon md-icon"></span> Blog</label><ul class=md-nav__list data-md-scrollfix><li class="md-nav__item md-nav__item--active"><a class=md-nav__link href=../../..> <span class=md-ellipsis> Blog </span> </a><li class="md-nav__item md-nav__item--nested"><input class="md-nav__toggle md-toggle md-toggle--indeterminate" id=__nav_1_2 type=checkbox> <label class=md-nav__link for=__nav_1_2 id=__nav_1_2_label tabindex=0><span class=md-ellipsis> 归档 </span> <span class="md-nav__icon md-icon"></span></label> <nav aria-expanded=false aria-labelledby=__nav_1_2_label class=md-nav data-md-level=2><label class=md-nav__title for=__nav_1_2><span class="md-nav__icon md-icon"></span> 归档</label><ul class=md-nav__list data-md-scrollfix><li class=md-nav__item><a class=md-nav__link href=../../../archive/2025/> <span class=md-ellipsis> 2025 </span> </a><li class=md-nav__item><a class=md-nav__link href=../../../archive/2024/> <span class=md-ellipsis> 2024 </span> </a><li class=md-nav__item><a class=md-nav__link href=../../../archive/2023/> <span class=md-ellipsis> 2023 </span> </a></ul></nav><li class="md-nav__item md-nav__item--nested"><input class="md-nav__toggle md-toggle md-toggle--indeterminate" id=__nav_1_3 type=checkbox> <label class=md-nav__link for=__nav_1_3 id=__nav_1_3_label tabindex=0><span class=md-ellipsis> 分类 </span> <span class="md-nav__icon md-icon"></span></label> <nav aria-expanded=false aria-labelledby=__nav_1_3_label class=md-nav data-md-level=2><label class=md-nav__title for=__nav_1_3><span class="md-nav__icon md-icon"></span> 分类</label><ul class=md-nav__list data-md-scrollfix><li class=md-nav__item><a class=md-nav__link href=../../../category/records-of-trivia/> <span class=md-ellipsis> Records of Trivia </span> </a><li class=md-nav__item><a class=md-nav__link href=../../../category/configure-debug/> <span class=md-ellipsis> Configure & Debug </span> </a><li class=md-nav__item><a class=md-nav__link href=../../../category/chronicle-of-events/> <span class=md-ellipsis> Chronicle of Events </span> </a></ul></nav></ul></nav></ul></nav></div></div></div><div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc><div class=md-sidebar__scrollwrap><div class=md-sidebar__inner><nav class="md-nav md-nav--secondary" aria-label=目录><label class=md-nav__title for=__toc><span class="md-nav__icon md-icon"></span> 目录</label><ul class=md-nav__list data-md-component=toc data-md-scrollfix><li class=md-nav__item><a class=md-nav__link href=#openp5> OpenP5 (第一次尝试但中断) </a> <nav aria-label="OpenP5 (第一次尝试但中断)" class=md-nav><ul class=md-nav__list><li class=md-nav__item><a class=md-nav__link href=#pyc> 解决 .pyc 文件导入问题 </a></ul></nav><li class=md-nav__item><a class=md-nav__link href=#_2> 报错 </a><li class=md-nav__item><a class=md-nav__link href=#genrec> GenRec (第一次尝试但中断) </a> <nav aria-label="GenRec (第一次尝试但中断)" class=md-nav><ul class=md-nav__list><li class=md-nav__item><a class=md-nav__link href=#huggingfaceco> 解决 huggingface.co 连接不上问题，成功使用离线模式 </a></ul></nav><li class=md-nav__item><a class=md-nav__link href=#openp5_1> OpenP5 (第二次尝试) </a></ul></nav></div></div></div><script defer src=https://cdn.jsdelivr.net/gh/RonaldLN/MyPamphlet-Blog@main/docs/javascripts/toc.js></script><link href=https://cdn.jsdelivr.net/gh/RonaldLN/MyPamphlet-Blog@main/docs/stylesheets/fold_toc.css rel=stylesheet><div class="md-content md-content--post" data-md-component=content><div class="md-sidebar md-sidebar--post" data-md-component=sidebar data-md-type=navigation><div class=md-sidebar__scrollwrap><div class="md-sidebar__inner md-post"><nav class="md-nav md-nav--primary"><div class=md-post__back><div class="md-nav__title md-nav__container"><a class=md-nav__link href=../../..> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg> <span class=md-ellipsis> 回到主页 </span> </a></div></div><div class="md-post__authors md-typeset"><div class="md-profile md-post__profile"><span class="md-author md-author--long"> <img alt="Ronald Luo" src="https://avatars.githubusercontent.com/u/120019179?v=4"> </span><span class=md-profile__description> <strong>Ronald Luo</strong><br> I'm A Student </span></div></div><ul class="md-post__meta md-nav__list"><li class="md-nav__item md-nav__item--section"><div class=md-post__title><span class=md-ellipsis> 元数据 </span></div> <nav class=md-nav><ul class=md-nav__list><li class=md-nav__item><div class=md-nav__link><svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M19 19H5V8h14m-3-7v2H8V1H6v2H5c-1.11 0-2 .89-2 2v14a2 2 0 0 0 2 2h14a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2h-1V1m-1 11h-5v5h5v-5Z"/></svg><time datetime="2023-10-04 00:00:00" class=md-ellipsis>2023年10月4日星期三</time></div><li class=md-nav__item><div class=md-nav__link><svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M9 3v15h3V3H9m3 2 4 13 3-1-4-13-3 1M5 5v13h3V5H5M3 19v2h18v-2H3Z"/></svg><span class=md-ellipsis> 分类于 <a href=../../../category/records-of-trivia/>Records of Trivia</a></span></div><li class=md-nav__item><div class=md-nav__link><svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M12 20a8 8 0 0 0 8-8 8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8m0-18a10 10 0 0 1 10 10 10 10 0 0 1-10 10C6.47 22 2 17.5 2 12A10 10 0 0 1 12 2m.5 5v5.25l4.5 2.67-.75 1.23L11 13V7h1.5Z"/></svg><span class=md-ellipsis> 需要 14 分钟阅读时间 </span></div></ul></nav></ul></nav></div></div></div><article class="md-content__inner md-typeset"><h1 id=_1>复现代码过程记录<a title="Permanent link" class=headerlink href=#_1>¶</a></h1><div style=opacity:.7;margin-top:-15px;font-size:.75em><p><span class=twemoji><svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M12 2A10 10 0 0 0 2 12a10 10 0 0 0 10 10 10 10 0 0 0 10-10h-2a8 8 0 0 1-8 8 8 8 0 0 1-8-8 8 8 0 0 1 8-8V2m6.78 1a.69.69 0 0 0-.48.2l-1.22 1.21 2.5 2.5L20.8 5.7c.26-.26.26-.7 0-.95L19.25 3.2c-.13-.13-.3-.2-.47-.2m-2.41 2.12L9 12.5V15h2.5l7.37-7.38-2.5-2.5Z"/></svg></span> 约 2191 个字 • <span class=twemoji><svg viewbox="0 0 640 512" xmlns=http://www.w3.org/2000/svg><path d="M392.8 1.2c-17-4.9-34.7 5-39.6 22l-128 448c-4.9 17 5 34.7 22 39.6s34.7-5 39.6-22l128-448c4.9-17-5-34.7-22-39.6zm80.6 120.1c-12.5 12.5-12.5 32.8 0 45.3l89.3 89.4-89.4 89.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l112-112c12.5-12.5 12.5-32.8 0-45.3l-112-112c-12.5-12.5-32.8-12.5-45.3 0zm-306.7 0c-12.5-12.5-32.8-12.5-45.3 0l-112 112c-12.5 12.5-12.5 32.8 0 45.3l112 112c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L77.3 256l89.4-89.4c12.5-12.5 12.5-32.8 0-45.3z"/></svg></span> 289 行代码</div><h2 id=openp5>OpenP5 (第一次尝试但中断)<a title="Permanent link" class=headerlink href=#openp5>¶</a></h2><p>论文网址：<p><a href=https://paperswithcode.com/paper/openp5-benchmarking-foundation-models-for>OpenP5: Benchmarking Foundation Models for Recommendation | Papers With Code</a><p>代码地址：<p><a href=https://github.com/agiresearch/OpenP5>agiresearch/OpenP5: OpenP5: An Open-source Platform for Developing, Fine-tuning, and Evaluating LLM-based Recommenders (github.com) - https://github.com/agiresearch/OpenP5</a><p>环境 <code>environment.txt</code> :<div class="language-text highlight"><pre><span></span><code><span id=__span-0-1><a href=#__codelineno-0-1 id=__codelineno-0-1 name=__codelineno-0-1></a>python==3.9.7
</span><span id=__span-0-2><a href=#__codelineno-0-2 id=__codelineno-0-2 name=__codelineno-0-2></a>transformers==4.26.0
</span><span id=__span-0-3><a href=#__codelineno-0-3 id=__codelineno-0-3 name=__codelineno-0-3></a>torch==1.8.1+cu111
</span><span id=__span-0-4><a href=#__codelineno-0-4 id=__codelineno-0-4 name=__codelineno-0-4></a>sklearn==1.1.2
</span><span id=__span-0-5><a href=#__codelineno-0-5 id=__codelineno-0-5 name=__codelineno-0-5></a>torchvision==0.9.1+cu111
</span><span id=__span-0-6><a href=#__codelineno-0-6 id=__codelineno-0-6 name=__codelineno-0-6></a>tqdm==4.64.1
</span><span id=__span-0-7><a href=#__codelineno-0-7 id=__codelineno-0-7 name=__codelineno-0-7></a>time
</span><span id=__span-0-8><a href=#__codelineno-0-8 id=__codelineno-0-8 name=__codelineno-0-8></a>collections
</span><span id=__span-0-9><a href=#__codelineno-0-9 id=__codelineno-0-9 name=__codelineno-0-9></a>argparse
</span><span id=__span-0-10><a href=#__codelineno-0-10 id=__codelineno-0-10 name=__codelineno-0-10></a>os
</span><span id=__span-0-11><a href=#__codelineno-0-11 id=__codelineno-0-11 name=__codelineno-0-11></a>sys
</span><span id=__span-0-12><a href=#__codelineno-0-12 id=__codelineno-0-12 name=__codelineno-0-12></a>numpy==1.23.1
</span></code></pre></div><p>由于 <code>time</code> <code>colloctions</code> <code>os</code> <code>sys</code> 好像都是自带的不能装，而 <code>torch</code> <code>torchvision</code> 需要装的是 cuda 版的，所以我将其修改为<div class="language-text highlight"><pre><span></span><code><span id=__span-1-1><a href=#__codelineno-1-1 id=__codelineno-1-1 name=__codelineno-1-1></a>transformers==4.26.0
</span><span id=__span-1-2><a href=#__codelineno-1-2 id=__codelineno-1-2 name=__codelineno-1-2></a>scikit-learn==1.1.2
</span><span id=__span-1-3><a href=#__codelineno-1-3 id=__codelineno-1-3 name=__codelineno-1-3></a>tqdm==4.64.1
</span><span id=__span-1-4><a href=#__codelineno-1-4 id=__codelineno-1-4 name=__codelineno-1-4></a>argparse
</span><span id=__span-1-5><a href=#__codelineno-1-5 id=__codelineno-1-5 name=__codelineno-1-5></a>numpy==1.23.1
</span></code></pre></div><p>其中 <code>sklearn</code> 在之前安装时发现说是更改成了 <code>scikit-learn</code> 所以我也进行了修改<p>这样就可以直接运行命令来安装对应的包<div class="language-bash highlight"><pre><span></span><code><span id=__span-2-1><a href=#__codelineno-2-1 id=__codelineno-2-1 name=__codelineno-2-1></a>pip<span class=w> </span>install<span class=w> </span>-r<span class=w> </span>environment.txt
</span></code></pre></div><hr><p>安装好这些后，打开 clone 的仓库，发现 <code>train.py</code> 中还是有一些报错<p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=../../../images/openp5_new_version.png><img alt=openp5_new_version src=../../../images/openp5_new_version.png></a><p>并且 <code>README.md</code> 中写着<blockquote><p>## Usage<p>Download the data from <a href="https://drive.google.com/drive/folders/1W5i5ryetj_gkcOpG1aZfL5Y8Yk6RxwYE?usp=sharing">Google Drive link</a>, and put them into <code>./data</code> folder.<p>The training command can be found in <code>./command</code> folder. Run the command such as<div class="language-bash highlight"><pre><span></span><code><span id=__span-3-1><a href=#__codelineno-3-1 id=__codelineno-3-1 name=__codelineno-3-1></a><span class=nb>cd</span><span class=w> </span><span class=nb>command</span>
</span><span id=__span-3-2><a href=#__codelineno-3-2 id=__codelineno-3-2 name=__codelineno-3-2></a>sh<span class=w> </span>ML1M_random.sh
</span></code></pre></div></blockquote><p>然而并没有 <code>./command</code> 文件夹，然后我发现，从main分支里下载的文件里面并没有command文件夹，<p>而有一个 old_version分支里面有，并且 <code>./command/ML1M_random.sh</code> 文件中的命令是要运行 <code>./src/main.py</code> 文件，而这个文件只在 old_version 分支中有，并且几乎所装的包都在 <code>main.py</code> 中被导入，所以我决定使用 old_version<hr><p>由于需要执行 <code>.sh</code> 文件，这个在windows的cmd中好像不能使用，只能在git bash终端中使用，而我又需要使用 conda 环境，<p>所以发现在 bash 中不能像cmd中一样运行 <code>conda activate openp5</code><p>搜索后发现了这个方法有效<p><a href=https://github.com/microsoft/vscode-python/issues/19534#issuecomment-1194774160>Conda environment fails to activate with Git Bash · Issue #19534 · microsoft/vscode-python (github.com)</a><blockquote><p><a href=https://ronaldln.github.io/MyPamphlet/系统%26环境/anaconda/#5>手册 - Anaconda</a></blockquote><p><code>source</code> anaconda3 安装路径下的 <code>/Scripts/activate</code><div class="language-bash highlight"><pre><span></span><code><span id=__span-4-1><a href=#__codelineno-4-1 id=__codelineno-4-1 name=__codelineno-4-1></a><span class=nb>source</span><span class=w> </span>/e/Programs/Anaconda3/Scripts/activate
</span></code></pre></div><p>然后就会启动 anaconda 的 base 环境，这时 <code>conda activate openp5</code> 就有可以使用 openp5 的虚拟环境了<hr><h3 id=pyc>解决 <code>.pyc</code> 文件导入问题<a title="Permanent link" class=headerlink href=#pyc>¶</a></h3><p>old_version的 <code>main.py</code> 中有一处报错，<p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=../../../images/openp5_old_version.png><img alt=openp5_old_version loading=lazy src=../../../images/openp5_old_version.png></a><p>是使用了自己的包，而好像 pycharm 中 <code>./src/model</code> 文件夹中并没有这个 <code>P5</code> 的东西<p>经过一顿折腾之后，偶然发现了，原本的仓库里面， <code>model</code> 文件夹下有一个 <code>__pycache__</code> 文件夹，里面有一个 <code>P5.cpython-39.pyc</code> 文件，我认为这个应该就是 <code>main.py</code> 要导的包，<p>所以开始查询如何在 pycharm 中才能导入这个包(因为最近也有一个类似的情况(编译Orbbec SDK) - 在终端中能使用/导入pyc文件，而在pycharm中会报错)，然后发现了<p><a href=https://stackoverflow.com/questions/64209855/cannot-see-pyc-files-in-pycharm>python - Cannot see pyc files in PyCharm - Stack Overflow</a><p>这个的<a href=https://stackoverflow.com/a/64214290>回答</a><p>需要在 pycharm 的 <strong><mark>设置 - 编辑器 - 文件类型 - 忽略的文件和文件夹</mark></strong> 里，把 <code>*.pyc</code> 和 <code>__pycache__</code> 去掉<hr><p>但经过测试之后发现，即使能看到pyc文件也还是会报错<p>想起来在 <a href=https://vcp.developer.orbbec.com.cn:9001/project-2/doc-70/#测试-sample>Orbbec SDK for Python 使用手册 测试 Sample</a> 里，终端上使用时，需要设置一个 <code>PYTHONPATH</code> 的环境变量，<div class="language-bash highlight"><pre><span></span><code><span id=__span-5-1><a href=#__codelineno-5-1 id=__codelineno-5-1 name=__codelineno-5-1></a><span class=c1># set PYTHONPATH environment variable to include the lib directory in the install directory</span>
</span><span id=__span-5-2><a href=#__codelineno-5-2 id=__codelineno-5-2 name=__codelineno-5-2></a><span class=nb>export</span><span class=w> </span><span class=nv>PYTHONPATH</span><span class=o>=</span><span class=nv>$PYTHONPATH</span>:<span class=k>$(</span><span class=nb>pwd</span><span class=k>)</span>/install/lib/
</span></code></pre></div><p>所以开始查询如何在 pycharm 中设置 <code>PYTHONPATH</code> 环境变量，然后从<p><a href=https://stackoverflow.com/questions/28326362/pycharm-and-pythonpath>python - PyCharm and PYTHONPATH - Stack Overflow</a><p><a href=https://www.jetbrains.com/help/pycharm/installing-uninstalling-and-reloading-interpreter-paths.html>Manage interpreter paths | PyCharm Documentation (jetbrains.com)</a><p>找到了方法：<p><strong><mark>设置 - 项目 - Python解释器 - 在 <code>Python 解释器:</code> 右侧的框的右侧点击向下的三角/箭头 - 全部显示 - 在左上角图标中找到 <code>显示解释器路径</code> - 添加相应的路径</mark></strong><p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=../../../images/show_paths_of_interpreter.png><img alt=show_paths_of_interpreter loading=lazy src=../../../images/show_paths_of_interpreter.png></a><p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=../../../images/add_paths_of_interpreter.png><img alt=add_paths_of_interpreter loading=lazy src=../../../images/add_paths_of_interpreter.png></a><p>由于 <code>main.py</code> 文件中，是<div class="language-python highlight"><pre><span></span><code><span id=__span-6-1><a href=#__codelineno-6-1 id=__codelineno-6-1 name=__codelineno-6-1></a><span class=kn>from</span><span class=w> </span><span class=nn>model.P5</span><span class=w> </span><span class=kn>import</span> <span class=n>P5</span>
</span></code></pre></div><p>所以应该是把 <code>model</code> 的父目录(即项目的根目录)添加上<div class="language-text highlight"><pre><span></span><code><span id=__span-7-1><a href=#__codelineno-7-1 id=__codelineno-7-1 name=__codelineno-7-1></a>E:\Github\code_reproduction\OpenP5-old_version
</span></code></pre></div><p>添加完了之后，即使还是会有红色的警告，但能运行了<p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=../../../images/run_openp5.png><img alt=run_openp5 loading=lazy src=../../../images/run_openp5.png></a><hr><h2 id=_2>报错<a title="Permanent link" class=headerlink href=#_2>¶</a></h2><details class=quote><summary>error info</summary> <div class="language-bash highlight"><pre><span></span><code><span id=__span-8-1><a href=#__codelineno-8-1 id=__codelineno-8-1 name=__codelineno-8-1></a>$<span class=w> </span>sh<span class=w> </span>ML1M_random.sh
</span><span id=__span-8-2><a href=#__codelineno-8-2 id=__codelineno-8-2 name=__codelineno-8-2></a><span class=o>{</span><span class=s1>'seed'</span>:<span class=w> </span><span class=m>2023</span>,<span class=w> </span><span class=s1>'model_dir'</span>:<span class=w> </span><span class=s1>'../model'</span>,<span class=w> </span><span class=s1>'checkpoint_dir'</span>:<span class=w> </span><span class=s1>'../checkpoint'</span>,<span class=w> </span><span class=s1>'model_name'</span>:<span class=w> </span><span class=s1>'model.pt'</span>,<span class=w> </span><span class=s1>'log_dir'</span>:<span class=w> </span><span class=s1>'../log'</span>,<span class=w> </span><span class=s1>'distributed'</span>:<span class=w> </span><span class=m>1</span>,<span class=w> </span><span class=s1>'gpu'</span>:<span class=w> </span><span class=s1>'0,1'</span>,<span class=w> </span><span class=s1>'master_addr'</span>:<span class=w> </span><span class=s1>'localhost'</span>,<span class=w> </span><span class=s1>'master_port'</span>:<span class=w> </span><span class=s1>'1991'</span>,<span class=w> </span><span class=s1>'logging_level'</span>:<span class=w> </span><span class=m>20</span>,<span class=w> </span><span class=s1>'data_path'</span>:<span class=w> </span><span class=s1>'../data'</span>,<span class=w> </span><span class=s1>'item_indexing'</span>:<span class=w> </span><span class=s1>'random'</span>,<span class=w> </span><span class=s1>'tasks'</span>:<span class=w> </span><span class=s1>'sequential,straightforward'</span>,<span class=w> </span><span class=s1>'datasets'</span>:<span class=w> </span><span class=s1>'ML1M'</span>,<span class=w> </span><span class=s1>'prompt_file'</span>:<span class=w> </span><span class=s1>'../prompt.txt'</span>,<span class=w> </span><span class=s1>'sequential_order'</span>:<span class=w> </span><span class=s1>'original'</span>,<span class=w> </span><span class=s1>'collaborative_token_size'</span>:<span class=w> </span><span class=m>200</span>,<span class=w> </span><span class=s1>'collaborative_cluster'</span>:<span class=w> </span><span class=m>20</span>,<span class=w> </span><span class=s1>'collaborative_last_token'</span>:<span class=w> </span><span class=s1>'sequential'</span>,<span class=w> </span><span class=s1>'collaborative_float32'</span>:<span class=w> </span><span class=m>0</span>,<span class=w> </span><span class=s1>'max_his'</span>:<span class=w> </span><span class=m>20</span>,<span class=w> </span><span class=s1>'his_prefix'</span>:<span class=w> </span><span class=m>1</span>,<span class=w> </span><span class=s1>'his_sep'</span>:<span class=w> </span><span class=s1>' , '</span>,<span class=w> </span><span class=s1>'skip_empty_his'</span>:<span class=w> </span><span class=m>1</span>,<span class=w> </span><span class=s1>'valid_prompt'</span>:<span class=w> </span><span class=s1>'seen:0'</span>,<span class=w> </span><span class=s1>'valid_prompt_sample'</span>:<span class=w> </span><span class=m>1</span>,<span class=w> </span><span class=s1>'valid_sample_num'</span>:<span class=w> </span><span class=s1>'3,3'</span>,<span class=w> </span><span class=s1>'test_prompt'</span>:<span class=w> </span><span class=s1>'seen:0'</span>,<span class=w> </span><span class=s1>'sample_prompt'</span>:<span class=w> </span><span class=m>1</span>,<span class=w> </span><span class=s1>'sample_num'</span>:<span class=w> </span><span class=s1>'3,3'</span>,<span class=w> </span><span class=s1>'batch_size'</span>:<span class=w> </span><span class=m>128</span>,<span class=w> </span><span class=s1>'eval_batch_size'</span>:<span class=w> </span><span class=m>20</span>,<span class=w> </span><span class=s1>'dist_sampler'</span>:<span class=w> </span><span class=m>0</span>,<span class=w> </span><span class=s1>'optim'</span>:<span class=w> </span><span class=s1>'AdamW'</span>,<span class=w> </span><span class=s1>'epochs'</span>:<span class=w> </span><span class=m>10</span>,<span class=w> </span><span class=s1>'lr'</span>:<span class=w> </span><span class=m>0</span>.001,<span class=w> </span><span class=s1>'clip'</span>:<span class=w> </span><span class=m>1</span>,<span class=w> </span><span class=s1>'logging_step'</span>:<span class=w> </span><span class=m>100</span>,<span class=w> </span><span class=s1>'warmup_prop'</span>:<span class=w> </span><span class=m>0</span>.05,<span class=w> </span><span class=s1>'gradient_accumulation_steps'</span>:<span class=w> </span><span class=m>1</span>,<span class=w> </span><span class=s1>'weight_decay'</span>:<span class=w> </span><span class=m>0</span>.01,<span class=w> </span><span class=s1>'adam_eps'</span>:<span class=w> </span>1e-06,<span class=w> </span><span class=s1>'dropout'</span>:<span class=w> </span><span class=m>0</span>.1,<span class=w> </span><span class=s1>'alpha'</span>:<span class=w> </span><span class=m>2</span>,<span class=w> </span><span class=s1>'train'</span>:<span class=w> </span><span class=m>1</span>,<span class=w> </span><span class=s1>'backbone'</span>:<span class=w> </span><span class=s1>'t5-small'</span>,<span class=w> </span><span class=s1>'metrics'</span>:<span class=w> </span><span class=s1>'hit@5,hit@10,ndcg@5,ndcg@10'</span>,<span class=w> </span><span class=s1>'load'</span>:<span class=w> </span><span class=m>0</span>,<span class=w> </span><span class=s1>'random_initialize'</span>:<span class=w> </span><span class=m>1</span>,<span class=w> </span><span class=s1>'test_epoch'</span>:<span class=w> </span><span class=m>0</span>,<span class=w> </span><span class=s1>'valid_select'</span>:<span class=w> </span><span class=m>0</span>,<span class=w> </span><span class=s1>'test_before_train'</span>:<span class=w> </span><span class=m>0</span>,<span class=w> </span><span class=s1>'test_filtered'</span>:<span class=w> </span><span class=m>0</span>,<span class=w> </span><span class=s1>'test_filtered_batch'</span>:<span class=w> </span><span class=m>1</span>,<span class=w> </span><span class=s1>'log_name'</span>:<span class=w> </span><span class=s1>'1_1_1_1_20_1991_ML1M_sequential,straightforward_t5-small_random_0.001_10_128_3,3_prompt'</span>,<span class=w> </span><span class=s1>'model_path'</span>:<span class=w> </span><span class=s1>'../model\\ML1M\\1_1_1_1_20_1991_ML1M_sequential,straightforward_t5-small_random_0.001_10_128_3,3_prompt.pt'</span>,<span class=w> </span><span class=s1>'rank'</span>:<span class=w> </span><span class=m>0</span><span class=o>}</span>
</span><span id=__span-8-3><a href=#__codelineno-8-3 id=__codelineno-8-3 name=__codelineno-8-3></a><span class=s1>'(MaxRetryError("HTTPSConnectionPool(host='</span>huggingface.co<span class=s1>', port=443): Max retries exceeded with url: /t5-small/resolve/main/tokenizer_config.json (Caused by ConnectTimeoutError(&lt;urllib3.connection.HTTPSConnection object at 0x0000018265B83BB0>, '</span>Connection<span class=w> </span>to<span class=w> </span>huggingface.co<span class=w> </span>timed<span class=w> </span>out.<span class=w> </span><span class=o>(</span>connect<span class=w> </span><span class=nv>timeout</span><span class=o>=</span><span class=m>10</span><span class=o>)</span><span class=s1>'))"), '</span><span class=o>(</span>Request<span class=w> </span>ID:<span class=w> </span>703c57e1-700e-4497-8fdf-3cf500baea63<span class=o>)</span><span class=s1>')'</span><span class=w> </span>thrown<span class=w> </span><span class=k>while</span><span class=w> </span>requesting<span class=w> </span>HEAD<span class=w> </span>https://huggingface.co/t5-small/resolve/main/tokenizer_config.json
</span><span id=__span-8-4><a href=#__codelineno-8-4 id=__codelineno-8-4 name=__codelineno-8-4></a><span class=s1>'(MaxRetryError("HTTPSConnectionPool(host='</span>huggingface.co<span class=s1>', port=443): Max retries exceeded with url: /t5-small/resolve/main/tokenizer_config.json (Caused by ConnectTimeoutError(&lt;urllib3.connection.HTTPSConnection object at 0x0000018265B83BB0>, '</span>Connection<span class=w> </span>to<span class=w> </span>huggingface.co<span class=w> </span>timed<span class=w> </span>out.<span class=w> </span><span class=o>(</span>connect<span class=w> </span><span class=nv>timeout</span><span class=o>=</span><span class=m>10</span><span class=o>)</span><span class=s1>'))"), '</span><span class=o>(</span>Request<span class=w> </span>ID:<span class=w> </span>703c57e1-700e-4497-8fdf-3cf500baea63<span class=o>)</span><span class=s1>')'</span><span class=w> </span>thrown<span class=w> </span><span class=k>while</span><span class=w> </span>requesting<span class=w> </span>HEAD<span class=w> </span>https://huggingface.co/t5-small/resolve/main/tokenizer_config.json
</span><span id=__span-8-5><a href=#__codelineno-8-5 id=__codelineno-8-5 name=__codelineno-8-5></a><span class=s1>'(MaxRetryError("HTTPSConnectionPool(host='</span>huggingface.co<span class=s1>', port=443): Max retries exceeded with url: /t5-small/resolve/main/config.json (Caused by ConnectTimeoutError(&lt;urllib3.connection.HTTPSConnection object at 0x000001821CE4F7C0>, '</span>Connection<span class=w> </span>to<span class=w> </span>huggingface.co<span class=w> </span>timed<span class=w> </span>out.<span class=w> </span><span class=o>(</span>connect<span class=w> </span><span class=nv>timeout</span><span class=o>=</span><span class=m>10</span><span class=o>)</span><span class=s1>'))"), '</span><span class=o>(</span>Request<span class=w> </span>ID:<span class=w> </span>fece3cd4-12a5-4ab5-b3a2-7fea10c749bf<span class=o>)</span><span class=s1>')'</span><span class=w> </span>thrown<span class=w> </span><span class=k>while</span><span class=w> </span>requesting<span class=w> </span>HEAD<span class=w> </span>https://huggingface.co/t5-small/resolve/main/config.json
</span><span id=__span-8-6><a href=#__codelineno-8-6 id=__codelineno-8-6 name=__codelineno-8-6></a><span class=s1>'(MaxRetryError("HTTPSConnectionPool(host='</span>huggingface.co<span class=s1>', port=443): Max retries exceeded with url: /t5-small/resolve/main/config.json (Caused by ConnectTimeoutError(&lt;urllib3.connection.HTTPSConnection object at 0x000001821CE4F7C0>, '</span>Connection<span class=w> </span>to<span class=w> </span>huggingface.co<span class=w> </span>timed<span class=w> </span>out.<span class=w> </span><span class=o>(</span>connect<span class=w> </span><span class=nv>timeout</span><span class=o>=</span><span class=m>10</span><span class=o>)</span><span class=s1>'))"), '</span><span class=o>(</span>Request<span class=w> </span>ID:<span class=w> </span>fece3cd4-12a5-4ab5-b3a2-7fea10c749bf<span class=o>)</span><span class=s1>')'</span><span class=w> </span>thrown<span class=w> </span><span class=k>while</span><span class=w> </span>requesting<span class=w> </span>HEAD<span class=w> </span>https://huggingface.co/t5-small/resolve/main/config.json
</span><span id=__span-8-7><a href=#__codelineno-8-7 id=__codelineno-8-7 name=__codelineno-8-7></a>Traceback<span class=w> </span><span class=o>(</span>most<span class=w> </span>recent<span class=w> </span>call<span class=w> </span>last<span class=o>)</span>:
</span><span id=__span-8-8><a href=#__codelineno-8-8 id=__codelineno-8-8 name=__codelineno-8-8></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\openp5\lib\site-packages\urllib3\connection.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>203</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>_new_conn
</span><span id=__span-8-9><a href=#__codelineno-8-9 id=__codelineno-8-9 name=__codelineno-8-9></a><span class=w>    </span><span class=nv>sock</span><span class=w> </span><span class=o>=</span><span class=w> </span>connection.create_connection<span class=o>(</span>
</span><span id=__span-8-10><a href=#__codelineno-8-10 id=__codelineno-8-10 name=__codelineno-8-10></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\openp5\lib\site-packages\urllib3\util\connection.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>85</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>create_connection
</span><span id=__span-8-11><a href=#__codelineno-8-11 id=__codelineno-8-11 name=__codelineno-8-11></a><span class=w>    </span>raise<span class=w> </span>err
</span><span id=__span-8-12><a href=#__codelineno-8-12 id=__codelineno-8-12 name=__codelineno-8-12></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\openp5\lib\site-packages\urllib3\util\connection.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>73</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>create_connection
</span><span id=__span-8-13><a href=#__codelineno-8-13 id=__codelineno-8-13 name=__codelineno-8-13></a><span class=w>    </span>sock.connect<span class=o>(</span>sa<span class=o>)</span>
</span><span id=__span-8-14><a href=#__codelineno-8-14 id=__codelineno-8-14 name=__codelineno-8-14></a>socket.timeout:<span class=w> </span>timed<span class=w> </span>out
</span><span id=__span-8-15><a href=#__codelineno-8-15 id=__codelineno-8-15 name=__codelineno-8-15></a>
</span><span id=__span-8-16><a href=#__codelineno-8-16 id=__codelineno-8-16 name=__codelineno-8-16></a>The<span class=w> </span>above<span class=w> </span>exception<span class=w> </span>was<span class=w> </span>the<span class=w> </span>direct<span class=w> </span>cause<span class=w> </span>of<span class=w> </span>the<span class=w> </span>following<span class=w> </span>exception:
</span><span id=__span-8-17><a href=#__codelineno-8-17 id=__codelineno-8-17 name=__codelineno-8-17></a>
</span><span id=__span-8-18><a href=#__codelineno-8-18 id=__codelineno-8-18 name=__codelineno-8-18></a>Traceback<span class=w> </span><span class=o>(</span>most<span class=w> </span>recent<span class=w> </span>call<span class=w> </span>last<span class=o>)</span>:
</span><span id=__span-8-19><a href=#__codelineno-8-19 id=__codelineno-8-19 name=__codelineno-8-19></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\openp5\lib\site-packages\urllib3\connectionpool.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>790</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>urlopen
</span><span id=__span-8-20><a href=#__codelineno-8-20 id=__codelineno-8-20 name=__codelineno-8-20></a><span class=w>    </span><span class=nv>response</span><span class=w> </span><span class=o>=</span><span class=w> </span>self._make_request<span class=o>(</span>
</span><span id=__span-8-21><a href=#__codelineno-8-21 id=__codelineno-8-21 name=__codelineno-8-21></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\openp5\lib\site-packages\urllib3\connectionpool.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>491</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>_make_request
</span><span id=__span-8-22><a href=#__codelineno-8-22 id=__codelineno-8-22 name=__codelineno-8-22></a><span class=w>    </span>raise<span class=w> </span>new_e
</span><span id=__span-8-23><a href=#__codelineno-8-23 id=__codelineno-8-23 name=__codelineno-8-23></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\openp5\lib\site-packages\urllib3\connectionpool.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>467</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>_make_request
</span><span id=__span-8-24><a href=#__codelineno-8-24 id=__codelineno-8-24 name=__codelineno-8-24></a><span class=w>    </span>self._validate_conn<span class=o>(</span>conn<span class=o>)</span>
</span><span id=__span-8-25><a href=#__codelineno-8-25 id=__codelineno-8-25 name=__codelineno-8-25></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\openp5\lib\site-packages\urllib3\connectionpool.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>1092</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>_validate_conn
</span><span id=__span-8-26><a href=#__codelineno-8-26 id=__codelineno-8-26 name=__codelineno-8-26></a><span class=w>    </span>conn.connect<span class=o>()</span>
</span><span id=__span-8-27><a href=#__codelineno-8-27 id=__codelineno-8-27 name=__codelineno-8-27></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\openp5\lib\site-packages\urllib3\connection.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>611</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>connect
</span><span id=__span-8-28><a href=#__codelineno-8-28 id=__codelineno-8-28 name=__codelineno-8-28></a><span class=w>    </span>self.sock<span class=w> </span><span class=o>=</span><span class=w> </span><span class=nv>sock</span><span class=w> </span><span class=o>=</span><span class=w> </span>self._new_conn<span class=o>()</span>
</span><span id=__span-8-29><a href=#__codelineno-8-29 id=__codelineno-8-29 name=__codelineno-8-29></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\openp5\lib\site-packages\urllib3\connection.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>212</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>_new_conn
</span><span id=__span-8-30><a href=#__codelineno-8-30 id=__codelineno-8-30 name=__codelineno-8-30></a><span class=w>    </span>raise<span class=w> </span>ConnectTimeoutError<span class=o>(</span>
</span><span id=__span-8-31><a href=#__codelineno-8-31 id=__codelineno-8-31 name=__codelineno-8-31></a>urllib3.exceptions.ConnectTimeoutError:<span class=w> </span><span class=o>(</span>&lt;urllib3.connection.HTTPSConnection<span class=w> </span>object<span class=w> </span>at<span class=w> </span>0x000001821CE4F7C0>,<span class=w> </span><span class=s1>'Connection to huggingface.co timed out. (connect timeout=10)'</span><span class=o>)</span>
</span><span id=__span-8-32><a href=#__codelineno-8-32 id=__codelineno-8-32 name=__codelineno-8-32></a>
</span><span id=__span-8-33><a href=#__codelineno-8-33 id=__codelineno-8-33 name=__codelineno-8-33></a>The<span class=w> </span>above<span class=w> </span>exception<span class=w> </span>was<span class=w> </span>the<span class=w> </span>direct<span class=w> </span>cause<span class=w> </span>of<span class=w> </span>the<span class=w> </span>following<span class=w> </span>exception:
</span><span id=__span-8-34><a href=#__codelineno-8-34 id=__codelineno-8-34 name=__codelineno-8-34></a>
</span><span id=__span-8-35><a href=#__codelineno-8-35 id=__codelineno-8-35 name=__codelineno-8-35></a>Traceback<span class=w> </span><span class=o>(</span>most<span class=w> </span>recent<span class=w> </span>call<span class=w> </span>last<span class=o>)</span>:
</span><span id=__span-8-36><a href=#__codelineno-8-36 id=__codelineno-8-36 name=__codelineno-8-36></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\openp5\lib\site-packages\requests\adapters.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>486</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>send
</span><span id=__span-8-37><a href=#__codelineno-8-37 id=__codelineno-8-37 name=__codelineno-8-37></a><span class=w>    </span><span class=nv>resp</span><span class=w> </span><span class=o>=</span><span class=w> </span>conn.urlopen<span class=o>(</span>
</span><span id=__span-8-38><a href=#__codelineno-8-38 id=__codelineno-8-38 name=__codelineno-8-38></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\openp5\lib\site-packages\urllib3\connectionpool.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>844</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>urlopen
</span><span id=__span-8-39><a href=#__codelineno-8-39 id=__codelineno-8-39 name=__codelineno-8-39></a><span class=w>    </span><span class=nv>retries</span><span class=w> </span><span class=o>=</span><span class=w> </span>retries.increment<span class=o>(</span>
</span><span id=__span-8-40><a href=#__codelineno-8-40 id=__codelineno-8-40 name=__codelineno-8-40></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\openp5\lib\site-packages\urllib3\util\retry.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>515</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>increment
</span><span id=__span-8-41><a href=#__codelineno-8-41 id=__codelineno-8-41 name=__codelineno-8-41></a><span class=w>    </span>raise<span class=w> </span>MaxRetryError<span class=o>(</span>_pool,<span class=w> </span>url,<span class=w> </span>reason<span class=o>)</span><span class=w> </span>from<span class=w> </span>reason<span class=w>  </span><span class=c1># type: ignore[arg-type]</span>
</span><span id=__span-8-42><a href=#__codelineno-8-42 id=__codelineno-8-42 name=__codelineno-8-42></a>urllib3.exceptions.MaxRetryError:<span class=w> </span>HTTPSConnectionPool<span class=o>(</span><span class=nv>host</span><span class=o>=</span><span class=s1>'huggingface.co'</span>,<span class=w> </span><span class=nv>port</span><span class=o>=</span><span class=m>443</span><span class=o>)</span>:<span class=w> </span>Max<span class=w> </span>retries<span class=w> </span>exceeded<span class=w> </span>with<span class=w> </span>url:<span class=w> </span>/t5-small/resolve/main/config.json<span class=w> </span><span class=o>(</span>Caused<span class=w> </span>by<span class=w> </span>ConnectTimeoutError<span class=o>(</span>&lt;urllib3.connection.HTTPSConnection<span class=w> </span>object<span class=w> </span>at<span class=w> </span>0x000001821CE4F7C0>,<span class=w> </span><span class=s1>'Connection to huggingface.co timed out. (connect timeout=10)'</span><span class=o>))</span>
</span><span id=__span-8-43><a href=#__codelineno-8-43 id=__codelineno-8-43 name=__codelineno-8-43></a>
</span><span id=__span-8-44><a href=#__codelineno-8-44 id=__codelineno-8-44 name=__codelineno-8-44></a>During<span class=w> </span>handling<span class=w> </span>of<span class=w> </span>the<span class=w> </span>above<span class=w> </span>exception,<span class=w> </span>another<span class=w> </span>exception<span class=w> </span>occurred:
</span><span id=__span-8-45><a href=#__codelineno-8-45 id=__codelineno-8-45 name=__codelineno-8-45></a>
</span><span id=__span-8-46><a href=#__codelineno-8-46 id=__codelineno-8-46 name=__codelineno-8-46></a>Traceback<span class=w> </span><span class=o>(</span>most<span class=w> </span>recent<span class=w> </span>call<span class=w> </span>last<span class=o>)</span>:
</span><span id=__span-8-47><a href=#__codelineno-8-47 id=__codelineno-8-47 name=__codelineno-8-47></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\openp5\lib\site-packages\huggingface_hub\file_download.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>1232</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>hf_hub_download
</span><span id=__span-8-48><a href=#__codelineno-8-48 id=__codelineno-8-48 name=__codelineno-8-48></a><span class=w>    </span><span class=nv>metadata</span><span class=w> </span><span class=o>=</span><span class=w> </span>get_hf_file_metadata<span class=o>(</span>
</span><span id=__span-8-49><a href=#__codelineno-8-49 id=__codelineno-8-49 name=__codelineno-8-49></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\openp5\lib\site-packages\huggingface_hub\utils\_validators.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>118</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>_inner_fn
</span><span id=__span-8-50><a href=#__codelineno-8-50 id=__codelineno-8-50 name=__codelineno-8-50></a><span class=w>    </span><span class=k>return</span><span class=w> </span>fn<span class=o>(</span>*args,<span class=w> </span>**kwargs<span class=o>)</span>
</span><span id=__span-8-51><a href=#__codelineno-8-51 id=__codelineno-8-51 name=__codelineno-8-51></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\openp5\lib\site-packages\huggingface_hub\file_download.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>1599</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>get_hf_file_metadata
</span><span id=__span-8-52><a href=#__codelineno-8-52 id=__codelineno-8-52 name=__codelineno-8-52></a><span class=w>    </span><span class=nv>r</span><span class=w> </span><span class=o>=</span><span class=w> </span>_request_wrapper<span class=o>(</span>
</span><span id=__span-8-53><a href=#__codelineno-8-53 id=__codelineno-8-53 name=__codelineno-8-53></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\openp5\lib\site-packages\huggingface_hub\file_download.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>417</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>_request_wrapper
</span><span id=__span-8-54><a href=#__codelineno-8-54 id=__codelineno-8-54 name=__codelineno-8-54></a><span class=w>    </span><span class=nv>response</span><span class=w> </span><span class=o>=</span><span class=w> </span>_request_wrapper<span class=o>(</span>
</span><span id=__span-8-55><a href=#__codelineno-8-55 id=__codelineno-8-55 name=__codelineno-8-55></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\openp5\lib\site-packages\huggingface_hub\file_download.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>452</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>_request_wrapper
</span><span id=__span-8-56><a href=#__codelineno-8-56 id=__codelineno-8-56 name=__codelineno-8-56></a><span class=w>    </span><span class=k>return</span><span class=w> </span>http_backoff<span class=o>(</span>
</span><span id=__span-8-57><a href=#__codelineno-8-57 id=__codelineno-8-57 name=__codelineno-8-57></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\openp5\lib\site-packages\huggingface_hub\utils\_http.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>274</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>http_backoff
</span><span id=__span-8-58><a href=#__codelineno-8-58 id=__codelineno-8-58 name=__codelineno-8-58></a><span class=w>    </span>raise<span class=w> </span>err
</span><span id=__span-8-59><a href=#__codelineno-8-59 id=__codelineno-8-59 name=__codelineno-8-59></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\openp5\lib\site-packages\huggingface_hub\utils\_http.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>258</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>http_backoff
</span><span id=__span-8-60><a href=#__codelineno-8-60 id=__codelineno-8-60 name=__codelineno-8-60></a><span class=w>    </span><span class=nv>response</span><span class=w> </span><span class=o>=</span><span class=w> </span>session.request<span class=o>(</span><span class=nv>method</span><span class=o>=</span>method,<span class=w> </span><span class=nv>url</span><span class=o>=</span>url,<span class=w> </span>**kwargs<span class=o>)</span>
</span><span id=__span-8-61><a href=#__codelineno-8-61 id=__codelineno-8-61 name=__codelineno-8-61></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\openp5\lib\site-packages\requests\sessions.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>589</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>request
</span><span id=__span-8-62><a href=#__codelineno-8-62 id=__codelineno-8-62 name=__codelineno-8-62></a><span class=w>    </span><span class=nv>resp</span><span class=w> </span><span class=o>=</span><span class=w> </span>self.send<span class=o>(</span>prep,<span class=w> </span>**send_kwargs<span class=o>)</span>
</span><span id=__span-8-63><a href=#__codelineno-8-63 id=__codelineno-8-63 name=__codelineno-8-63></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\openp5\lib\site-packages\requests\sessions.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>703</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>send
</span><span id=__span-8-64><a href=#__codelineno-8-64 id=__codelineno-8-64 name=__codelineno-8-64></a><span class=w>    </span><span class=nv>r</span><span class=w> </span><span class=o>=</span><span class=w> </span>adapter.send<span class=o>(</span>request,<span class=w> </span>**kwargs<span class=o>)</span>
</span><span id=__span-8-65><a href=#__codelineno-8-65 id=__codelineno-8-65 name=__codelineno-8-65></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\openp5\lib\site-packages\huggingface_hub\utils\_http.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>63</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>send
</span><span id=__span-8-66><a href=#__codelineno-8-66 id=__codelineno-8-66 name=__codelineno-8-66></a><span class=w>    </span><span class=k>return</span><span class=w> </span>super<span class=o>()</span>.send<span class=o>(</span>request,<span class=w> </span>*args,<span class=w> </span>**kwargs<span class=o>)</span>
</span><span id=__span-8-67><a href=#__codelineno-8-67 id=__codelineno-8-67 name=__codelineno-8-67></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\openp5\lib\site-packages\requests\adapters.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>507</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>send
</span><span id=__span-8-68><a href=#__codelineno-8-68 id=__codelineno-8-68 name=__codelineno-8-68></a><span class=w>    </span>raise<span class=w> </span>ConnectTimeout<span class=o>(</span>e,<span class=w> </span><span class=nv>request</span><span class=o>=</span>request<span class=o>)</span>
</span><span id=__span-8-69><a href=#__codelineno-8-69 id=__codelineno-8-69 name=__codelineno-8-69></a>requests.exceptions.ConnectTimeout:<span class=w> </span><span class=o>(</span>MaxRetryError<span class=o>(</span><span class=s2>"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /t5-small/resolve/main/config.json (Caused by ConnectTimeoutError(&lt;urllib3.connection.HTTPSConnection object at 0x000001821CE4F7C0>, 'Connection to huggingface.co timed out. (connect timeout=10)'))"</span><span class=o>)</span>,<span class=w> </span><span class=s1>'(Request ID: fece3cd4-12a5-4ab5-b3a2-7fea10c749bf)'</span><span class=o>)</span>
</span><span id=__span-8-70><a href=#__codelineno-8-70 id=__codelineno-8-70 name=__codelineno-8-70></a>
</span><span id=__span-8-71><a href=#__codelineno-8-71 id=__codelineno-8-71 name=__codelineno-8-71></a>The<span class=w> </span>above<span class=w> </span>exception<span class=w> </span>was<span class=w> </span>the<span class=w> </span>direct<span class=w> </span>cause<span class=w> </span>of<span class=w> </span>the<span class=w> </span>following<span class=w> </span>exception:
</span><span id=__span-8-72><a href=#__codelineno-8-72 id=__codelineno-8-72 name=__codelineno-8-72></a>
</span><span id=__span-8-73><a href=#__codelineno-8-73 id=__codelineno-8-73 name=__codelineno-8-73></a>Traceback<span class=w> </span><span class=o>(</span>most<span class=w> </span>recent<span class=w> </span>call<span class=w> </span>last<span class=o>)</span>:
</span><span id=__span-8-74><a href=#__codelineno-8-74 id=__codelineno-8-74 name=__codelineno-8-74></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\openp5\lib\site-packages\transformers\utils\hub.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>409</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>cached_file
</span><span id=__span-8-75><a href=#__codelineno-8-75 id=__codelineno-8-75 name=__codelineno-8-75></a><span class=w>    </span><span class=nv>resolved_file</span><span class=w> </span><span class=o>=</span><span class=w> </span>hf_hub_download<span class=o>(</span>
</span><span id=__span-8-76><a href=#__codelineno-8-76 id=__codelineno-8-76 name=__codelineno-8-76></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\openp5\lib\site-packages\huggingface_hub\utils\_validators.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>118</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>_inner_fn
</span><span id=__span-8-77><a href=#__codelineno-8-77 id=__codelineno-8-77 name=__codelineno-8-77></a><span class=w>    </span><span class=k>return</span><span class=w> </span>fn<span class=o>(</span>*args,<span class=w> </span>**kwargs<span class=o>)</span>
</span><span id=__span-8-78><a href=#__codelineno-8-78 id=__codelineno-8-78 name=__codelineno-8-78></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\openp5\lib\site-packages\huggingface_hub\file_download.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>1349</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>hf_hub_download
</span><span id=__span-8-79><a href=#__codelineno-8-79 id=__codelineno-8-79 name=__codelineno-8-79></a><span class=w>    </span>raise<span class=w> </span>LocalEntryNotFoundError<span class=o>(</span>
</span><span id=__span-8-80><a href=#__codelineno-8-80 id=__codelineno-8-80 name=__codelineno-8-80></a>huggingface_hub.utils._errors.LocalEntryNotFoundError:<span class=w> </span>An<span class=w> </span>error<span class=w> </span>happened<span class=w> </span><span class=k>while</span><span class=w> </span>trying<span class=w> </span>to<span class=w> </span>locate<span class=w> </span>the<span class=w> </span>file<span class=w> </span>on<span class=w> </span>the<span class=w> </span>Hub<span class=w> </span>and<span class=w> </span>we<span class=w> </span>cannot<span class=w> </span>find<span class=w> </span>the<span class=w> </span>requested<span class=w> </span>files<span class=w> </span><span class=k>in</span><span class=w> </span>the<span class=w> </span><span class=nb>local</span><span class=w> </span>cache.<span class=w> </span>Please<span class=w> </span>check<span class=w> </span>your<span class=w> </span>connection<span class=w> </span>and<span class=w> </span>try<span class=w> </span>again<span class=w> </span>or<span class=w> </span>make<span class=w> </span>sure<span class=w> </span>your<span class=w> </span>Internet<span class=w> </span>connection<span class=w> </span>is<span class=w> </span>on.
</span><span id=__span-8-81><a href=#__codelineno-8-81 id=__codelineno-8-81 name=__codelineno-8-81></a>
</span><span id=__span-8-82><a href=#__codelineno-8-82 id=__codelineno-8-82 name=__codelineno-8-82></a>During<span class=w> </span>handling<span class=w> </span>of<span class=w> </span>the<span class=w> </span>above<span class=w> </span>exception,<span class=w> </span>another<span class=w> </span>exception<span class=w> </span>occurred:
</span><span id=__span-8-83><a href=#__codelineno-8-83 id=__codelineno-8-83 name=__codelineno-8-83></a>
</span><span id=__span-8-84><a href=#__codelineno-8-84 id=__codelineno-8-84 name=__codelineno-8-84></a>Traceback<span class=w> </span><span class=o>(</span>most<span class=w> </span>recent<span class=w> </span>call<span class=w> </span>last<span class=o>)</span>:
</span><span id=__span-8-85><a href=#__codelineno-8-85 id=__codelineno-8-85 name=__codelineno-8-85></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Github\code_reproduction\OpenP5-old_version\src\main.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>233</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>&lt;module>
</span><span id=__span-8-86><a href=#__codelineno-8-86 id=__codelineno-8-86 name=__codelineno-8-86></a><span class=w>    </span>single_main<span class=o>()</span>
</span><span id=__span-8-87><a href=#__codelineno-8-87 id=__codelineno-8-87 name=__codelineno-8-87></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Github\code_reproduction\OpenP5-old_version\src\main.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>92</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>single_main
</span><span id=__span-8-88><a href=#__codelineno-8-88 id=__codelineno-8-88 name=__codelineno-8-88></a><span class=w>    </span><span class=nv>tokenizer</span><span class=w> </span><span class=o>=</span><span class=w> </span>AutoTokenizer.from_pretrained<span class=o>(</span>args.backbone<span class=o>)</span>
</span><span id=__span-8-89><a href=#__codelineno-8-89 id=__codelineno-8-89 name=__codelineno-8-89></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\openp5\lib\site-packages\transformers\models\auto\tokenization_auto.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>613</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>from_pretrained
</span><span id=__span-8-90><a href=#__codelineno-8-90 id=__codelineno-8-90 name=__codelineno-8-90></a><span class=w>    </span><span class=nv>config</span><span class=w> </span><span class=o>=</span><span class=w> </span>AutoConfig.from_pretrained<span class=o>(</span>
</span><span id=__span-8-91><a href=#__codelineno-8-91 id=__codelineno-8-91 name=__codelineno-8-91></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\openp5\lib\site-packages\transformers\models\auto\configuration_auto.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>852</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>from_pretrained
</span><span id=__span-8-92><a href=#__codelineno-8-92 id=__codelineno-8-92 name=__codelineno-8-92></a><span class=w>    </span>config_dict,<span class=w> </span><span class=nv>unused_kwargs</span><span class=w> </span><span class=o>=</span><span class=w> </span>PretrainedConfig.get_config_dict<span class=o>(</span>pretrained_model_name_or_path,<span class=w> </span>**kwargs<span class=o>)</span>
</span><span id=__span-8-93><a href=#__codelineno-8-93 id=__codelineno-8-93 name=__codelineno-8-93></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\openp5\lib\site-packages\transformers\configuration_utils.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>565</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>get_config_dict
</span><span id=__span-8-94><a href=#__codelineno-8-94 id=__codelineno-8-94 name=__codelineno-8-94></a><span class=w>    </span>config_dict,<span class=w> </span><span class=nv>kwargs</span><span class=w> </span><span class=o>=</span><span class=w> </span>cls._get_config_dict<span class=o>(</span>pretrained_model_name_or_path,<span class=w> </span>**kwargs<span class=o>)</span>
</span><span id=__span-8-95><a href=#__codelineno-8-95 id=__codelineno-8-95 name=__codelineno-8-95></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\openp5\lib\site-packages\transformers\configuration_utils.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>620</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>_get_config_dict
</span><span id=__span-8-96><a href=#__codelineno-8-96 id=__codelineno-8-96 name=__codelineno-8-96></a><span class=w>    </span><span class=nv>resolved_config_file</span><span class=w> </span><span class=o>=</span><span class=w> </span>cached_file<span class=o>(</span>
</span><span id=__span-8-97><a href=#__codelineno-8-97 id=__codelineno-8-97 name=__codelineno-8-97></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\openp5\lib\site-packages\transformers\utils\hub.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>443</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>cached_file
</span><span id=__span-8-98><a href=#__codelineno-8-98 id=__codelineno-8-98 name=__codelineno-8-98></a><span class=w>    </span>raise<span class=w> </span>EnvironmentError<span class=o>(</span>
</span><span id=__span-8-99><a href=#__codelineno-8-99 id=__codelineno-8-99 name=__codelineno-8-99></a>OSError:<span class=w> </span>We<span class=w> </span>couldn<span class=s1>'t connect to '</span>https://huggingface.co<span class=s1>' to load this file, couldn'</span>t<span class=w> </span>find<span class=w> </span>it<span class=w> </span><span class=k>in</span><span class=w> </span>the<span class=w> </span>cached<span class=w> </span>files<span class=w> </span>and<span class=w> </span>it<span class=w> </span>looks<span class=w> </span>like<span class=w> </span>t5-small<span class=w> </span>is<span class=w> </span>not<span class=w> </span>the<span class=w> </span>path<span class=w> </span>to<span class=w> </span>a<span class=w> </span>directory<span class=w> </span>containing<span class=w> </span>a<span class=w> </span>file<span class=w> </span>named<span class=w> </span>config.json.
</span><span id=__span-8-100><a href=#__codelineno-8-100 id=__codelineno-8-100 name=__codelineno-8-100></a>Checkout<span class=w> </span>your<span class=w> </span>internet<span class=w> </span>connection<span class=w> </span>or<span class=w> </span>see<span class=w> </span>how<span class=w> </span>to<span class=w> </span>run<span class=w> </span>the<span class=w> </span>library<span class=w> </span><span class=k>in</span><span class=w> </span>offline<span class=w> </span>mode<span class=w> </span>at<span class=w> </span><span class=s1>'https://huggingface.co/docs/transformers/installation#offline-mode'</span>.
</span></code></pre></div></details><h2 id=genrec>GenRec (第一次尝试但中断)<a title="Permanent link" class=headerlink href=#genrec>¶</a></h2><p>由于上一个代码暂时解决不了 <code>OSError: We couldn't connect to 'https://huggingface.co' to load this file ...</code> 的报错，所以开始尝试这篇论文的代码<p>论文网址：<p><a href=https://paperswithcode.com/paper/text-based-large-language-model-for>GenRec: Large Language Model for Generative Recommendation | Papers With Code</a><p>代码地址：<p><a href=https://github.com/rutgerswiselab/genrec>rutgerswiselab/GenRec: Large Language Model for Generative Recommendation (github.com)</a><p>安装好环境之后，初次运行发现<div class="language-bash highlight"><pre><span></span><code><span id=__span-9-1><a href=#__codelineno-9-1 id=__codelineno-9-1 name=__codelineno-9-1></a>ModuleNotFoundError:<span class=w> </span>No<span class=w> </span>module<span class=w> </span>named<span class=w> </span><span class=s1>'scipy'</span>
</span></code></pre></div><p>于是安装 <code>scipy</code><p>然后再运行<div class="language-bash highlight"><pre><span></span><code><span id=__span-10-1><a href=#__codelineno-10-1 id=__codelineno-10-1 name=__codelineno-10-1></a>ImportError:<span class=w> </span>Using<span class=w> </span><span class=sb>`</span><span class=nv>load_in_8bit</span><span class=o>=</span>True<span class=sb>`</span><span class=w> </span>requires<span class=w> </span>Accelerate:<span class=w> </span><span class=sb>`</span>pip<span class=w> </span>install<span class=w> </span>accelerate<span class=sb>`</span><span class=w> </span>and<span class=w> </span>the<span class=w> </span>latest<span class=w> </span>version<span class=w> </span>of<span class=w> </span>bitsandbytes<span class=w> </span><span class=sb>`</span>pip<span class=w> </span>install<span class=w> </span>-i<span class=w> </span>https://test.pypi.org/simple/<span class=w> </span>bitsandbytes<span class=sb>`</span><span class=w> </span>or<span class=w> </span>pip<span class=w> </span>install<span class=w> </span>bitsandbytes<span class=sb>`</span>
</span></code></pre></div><p>尝试 <code>pip install accelerate</code> 和 <code>pip install -i https://test.pypi.org/simple/ bitsandbytes</code> 后，显示都安装了，所以上网查找相关信息，然后发现两个 <strong><mark>不久前的回答</mark></strong><ul><li><p><a href=https://stackoverflow.com/questions/76924239/accelerate-and-bitsandbytes-is-needed-to-install-but-i-did>python - Accelerate and bitsandbytes is needed to install but I did - Stack Overflow</a></p> <p>中 <a href=https://stackoverflow.com/a/76976563>jason的回答</a></p><li><p><a href=https://huggingface.co/anon8231489123/vicuna-13b-GPTQ-4bit-128g/discussions/11>anon8231489123/vicuna-13b-GPTQ-4bit-128g · I keep getting this: ImportError: Using <code>load_in_8bit=True</code> requires Accelerate (huggingface.co)</a></p> <p>中 <a href=https://huggingface.co/anon8231489123/vicuna-13b-GPTQ-4bit-128g/discussions/11#650c4ea403e1ec1fc2ff0714>anudeepadi的回答</a></p></ul><p>都说了将 <code>transformers</code> 的版本<em>降级 downgrade</em> 到 <code>4.30</code> 就好了(我本来自动安装的版本是 <code>4.35.0.dev0</code> )(这个 <code>transformers</code> 怎么这么麻烦，上一篇论文也是弄这玩意弄了好久😡🤬)<p>修改以后发现可以运行了<p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=../../../images/run_genrec.png><img alt=run_genrec loading=lazy src=../../../images/run_genrec.png></a><p>最后出现这样的报错<div class="language-bash highlight"><pre><span></span><code><span id=__span-11-1><a href=#__codelineno-11-1 id=__codelineno-11-1 name=__codelineno-11-1></a>Traceback<span class=w> </span><span class=o>(</span>most<span class=w> </span>recent<span class=w> </span>call<span class=w> </span>last<span class=o>)</span>:
</span><span id=__span-11-2><a href=#__codelineno-11-2 id=__codelineno-11-2 name=__codelineno-11-2></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Github\code_reproduction\GenRec\rec.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>289</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>&lt;module>
</span><span id=__span-11-3><a href=#__codelineno-11-3 id=__codelineno-11-3 name=__codelineno-11-3></a><span class=w>    </span>fire.Fire<span class=o>(</span>train<span class=o>)</span>
</span><span id=__span-11-4><a href=#__codelineno-11-4 id=__codelineno-11-4 name=__codelineno-11-4></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\genrec\lib\site-packages\fire\core.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>141</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>Fire
</span><span id=__span-11-5><a href=#__codelineno-11-5 id=__codelineno-11-5 name=__codelineno-11-5></a><span class=w>    </span><span class=nv>component_trace</span><span class=w> </span><span class=o>=</span><span class=w> </span>_Fire<span class=o>(</span>component,<span class=w> </span>args,<span class=w> </span>parsed_flag_args,<span class=w> </span>context,<span class=w> </span>name<span class=o>)</span>
</span><span id=__span-11-6><a href=#__codelineno-11-6 id=__codelineno-11-6 name=__codelineno-11-6></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\genrec\lib\site-packages\fire\core.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>475</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>_Fire
</span><span id=__span-11-7><a href=#__codelineno-11-7 id=__codelineno-11-7 name=__codelineno-11-7></a><span class=w>    </span>component,<span class=w> </span><span class=nv>remaining_args</span><span class=w> </span><span class=o>=</span><span class=w> </span>_CallAndUpdateTrace<span class=o>(</span>
</span><span id=__span-11-8><a href=#__codelineno-11-8 id=__codelineno-11-8 name=__codelineno-11-8></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\genrec\lib\site-packages\fire\core.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>691</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>_CallAndUpdateTrace
</span><span id=__span-11-9><a href=#__codelineno-11-9 id=__codelineno-11-9 name=__codelineno-11-9></a><span class=w>    </span><span class=nv>component</span><span class=w> </span><span class=o>=</span><span class=w> </span>fn<span class=o>(</span>*varargs,<span class=w> </span>**kwargs<span class=o>)</span>
</span><span id=__span-11-10><a href=#__codelineno-11-10 id=__codelineno-11-10 name=__codelineno-11-10></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Github\code_reproduction\GenRec\rec.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>104</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>train
</span><span id=__span-11-11><a href=#__codelineno-11-11 id=__codelineno-11-11 name=__codelineno-11-11></a><span class=w>    </span><span class=nv>model</span><span class=w> </span><span class=o>=</span><span class=w> </span>LlamaForCausalLM.from_pretrained<span class=o>(</span>
</span><span id=__span-11-12><a href=#__codelineno-11-12 id=__codelineno-11-12 name=__codelineno-11-12></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\genrec\lib\site-packages\transformers\modeling_utils.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>2819</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>from_pretrained
</span><span id=__span-11-13><a href=#__codelineno-11-13 id=__codelineno-11-13 name=__codelineno-11-13></a><span class=w>    </span>raise<span class=w> </span>ValueError<span class=o>(</span>
</span><span id=__span-11-14><a href=#__codelineno-11-14 id=__codelineno-11-14 name=__codelineno-11-14></a>ValueError:
</span><span id=__span-11-15><a href=#__codelineno-11-15 id=__codelineno-11-15 name=__codelineno-11-15></a><span class=w>                        </span>Some<span class=w> </span>modules<span class=w> </span>are<span class=w> </span>dispatched<span class=w> </span>on<span class=w> </span>the<span class=w> </span>CPU<span class=w> </span>or<span class=w> </span>the<span class=w> </span>disk.<span class=w> </span>Make<span class=w> </span>sure<span class=w> </span>you<span class=w> </span>have<span class=w> </span>enough<span class=w> </span>GPU<span class=w> </span>RAM<span class=w> </span>to<span class=w> </span>fit
</span><span id=__span-11-16><a href=#__codelineno-11-16 id=__codelineno-11-16 name=__codelineno-11-16></a><span class=w>                        </span>the<span class=w> </span>quantized<span class=w> </span>model.<span class=w> </span>If<span class=w> </span>you<span class=w> </span>want<span class=w> </span>to<span class=w> </span>dispatch<span class=w> </span>the<span class=w> </span>model<span class=w> </span>on<span class=w> </span>the<span class=w> </span>CPU<span class=w> </span>or<span class=w> </span>the<span class=w> </span>disk<span class=w> </span><span class=k>while</span><span class=w> </span>keeping
</span><span id=__span-11-17><a href=#__codelineno-11-17 id=__codelineno-11-17 name=__codelineno-11-17></a><span class=w>                        </span>these<span class=w> </span>modules<span class=w> </span><span class=k>in</span><span class=w> </span><span class=m>32</span>-bit,<span class=w> </span>you<span class=w> </span>need<span class=w> </span>to<span class=w> </span><span class=nb>set</span><span class=w> </span><span class=sb>`</span><span class=nv>load_in_8bit_fp32_cpu_offload</span><span class=o>=</span>True<span class=sb>`</span><span class=w> </span>and<span class=w> </span>pass<span class=w> </span>a<span class=w> </span>custom
</span><span id=__span-11-18><a href=#__codelineno-11-18 id=__codelineno-11-18 name=__codelineno-11-18></a><span class=w>                        </span><span class=sb>`</span>device_map<span class=sb>`</span><span class=w> </span>to<span class=w> </span><span class=sb>`</span>from_pretrained<span class=sb>`</span>.<span class=w> </span>Check
</span><span id=__span-11-19><a href=#__codelineno-11-19 id=__codelineno-11-19 name=__codelineno-11-19></a><span class=w>                        </span>https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu
</span><span id=__span-11-20><a href=#__codelineno-11-20 id=__codelineno-11-20 name=__codelineno-11-20></a><span class=w>                        </span><span class=k>for</span><span class=w> </span>more<span class=w> </span>details.
</span></code></pre></div><hr><blockquote><p>(10.6)</blockquote><p>我怀疑可能是因为这个环境没有装 cuda 的原因，所以打算换用之前 OpenP5 的环境，于是开始安装对相应的包<p>由于出现了相似的网络问题，<blockquote><div class="language-bash highlight"><pre><span></span><code><span id=__span-12-1><a href=#__codelineno-12-1 id=__codelineno-12-1 name=__codelineno-12-1></a>pip<span class=w> </span>install<span class=w> </span>-r<span class=w> </span>requirements.txt
</span></code></pre></div><p><code>requirements.txt</code> 中有几个需要从 github 上安装包<div class="language-text highlight"><pre><span></span><code><span id=__span-13-1><a href=#__codelineno-13-1 id=__codelineno-13-1 name=__codelineno-13-1></a>git+https://github.com/huggingface/peft.git
</span><span id=__span-13-2><a href=#__codelineno-13-2 id=__codelineno-13-2 name=__codelineno-13-2></a>git+https://github.com/huggingface/transformers.git
</span></code></pre></div></blockquote><p>我打算直接 <code>pip install peft</code> ( <code>transformers</code> 之前 <code>openp5</code> 环境上已经安装过了)<p>安装时，把之前环境中的 <code>torch-1.8.1+cu111</code> 卸载了<div class="language-bash highlight"><pre><span></span><code><span id=__span-14-1><a href=#__codelineno-14-1 id=__codelineno-14-1 name=__codelineno-14-1></a>Installing<span class=w> </span>collected<span class=w> </span>packages:<span class=w> </span>mpmath,<span class=w> </span>sympy,<span class=w> </span>psutil,<span class=w> </span>networkx,<span class=w> </span>MarkupSafe,<span class=w> </span>jinja2,<span class=w> </span>torch
</span><span id=__span-14-2><a href=#__codelineno-14-2 id=__codelineno-14-2 name=__codelineno-14-2></a><span class=w>  </span>Attempting<span class=w> </span>uninstall:<span class=w> </span>torch
</span><span id=__span-14-3><a href=#__codelineno-14-3 id=__codelineno-14-3 name=__codelineno-14-3></a><span class=w>    </span>Found<span class=w> </span>existing<span class=w> </span>installation:<span class=w> </span>torch<span class=w> </span><span class=m>1</span>.8.1+cu111
</span><span id=__span-14-4><a href=#__codelineno-14-4 id=__codelineno-14-4 name=__codelineno-14-4></a><span class=w>    </span>Uninstalling<span class=w> </span>torch-1.8.1+cu111:
</span><span id=__span-14-5><a href=#__codelineno-14-5 id=__codelineno-14-5 name=__codelineno-14-5></a><span class=w>      </span>Successfully<span class=w> </span>uninstalled<span class=w> </span>torch-1.8.1+cu111
</span></code></pre></div><p>所以在结束后又重新安装了(还好之前的 <code>.whl</code> 文件还保留着)<div class="language-bash highlight"><pre><span></span><code><span id=__span-15-1><a href=#__codelineno-15-1 id=__codelineno-15-1 name=__codelineno-15-1></a>pip<span class=w> </span>install<span class=w> </span><span class=s2>"torch-1.8.1+cu111-cp39-cp39-win_amd64.whl"</span>
</span></code></pre></div><p>但是发现 <code>peft</code> 和 <code>accelerate</code> 要求更高版本的torch，<div class="language-bash highlight"><pre><span></span><code><span id=__span-16-1><a href=#__codelineno-16-1 id=__codelineno-16-1 name=__codelineno-16-1></a>peft<span class=w> </span><span class=m>0</span>.6.0.dev0<span class=w> </span>requires<span class=w> </span>torch><span class=o>=</span><span class=m>1</span>.13.0,<span class=w> </span>but<span class=w> </span>you<span class=w> </span>have<span class=w> </span>torch<span class=w> </span><span class=m>1</span>.8.1+cu111<span class=w> </span>which<span class=w> </span>is<span class=w> </span>incompatible.
</span><span id=__span-16-2><a href=#__codelineno-16-2 id=__codelineno-16-2 name=__codelineno-16-2></a>accelerate<span class=w> </span><span class=m>0</span>.23.0<span class=w> </span>requires<span class=w> </span>torch><span class=o>=</span><span class=m>1</span>.10.0,<span class=w> </span>but<span class=w> </span>you<span class=w> </span>have<span class=w> </span>torch<span class=w> </span><span class=m>1</span>.8.1+cu111<span class=w> </span>which<span class=w> </span>is<span class=w> </span>incompatible.
</span></code></pre></div><p>所以我打算安装版本低一些 <code>peft</code> 和 <code>accelerate</code><hr><p>发现 peft 0.4.x 的版本也要求torch最低版本1.13，所以我打算直接给原来的 <code>genrec</code> 环境安装新的 torch ，<p>但是发现，torch 1.13 最低只支持 11.6 的 cuda ，因此又安装了 11.6 的 cuda ， 然后安装了 torch-1.13.0+cu116<p>然后运行就和之前显示的信息不一样了<div class="language-bash highlight"><pre><span></span><code><span id=__span-17-1><a href=#__codelineno-17-1 id=__codelineno-17-1 name=__codelineno-17-1></a>RuntimeError:
</span><span id=__span-17-2><a href=#__codelineno-17-2 id=__codelineno-17-2 name=__codelineno-17-2></a><span class=w>        </span>CUDA<span class=w> </span>Setup<span class=w> </span>failed<span class=w> </span>despite<span class=w> </span>GPU<span class=w> </span>being<span class=w> </span>available.<span class=w> </span>Please<span class=w> </span>run<span class=w> </span>the<span class=w> </span>following<span class=w> </span><span class=nb>command</span><span class=w> </span>to<span class=w> </span>get<span class=w> </span>more<span class=w> </span>information:
</span><span id=__span-17-3><a href=#__codelineno-17-3 id=__codelineno-17-3 name=__codelineno-17-3></a>
</span><span id=__span-17-4><a href=#__codelineno-17-4 id=__codelineno-17-4 name=__codelineno-17-4></a><span class=w>        </span>python<span class=w> </span>-m<span class=w> </span>bitsandbytes
</span><span id=__span-17-5><a href=#__codelineno-17-5 id=__codelineno-17-5 name=__codelineno-17-5></a>
</span><span id=__span-17-6><a href=#__codelineno-17-6 id=__codelineno-17-6 name=__codelineno-17-6></a><span class=w>        </span>Inspect<span class=w> </span>the<span class=w> </span>output<span class=w> </span>of<span class=w> </span>the<span class=w> </span><span class=nb>command</span><span class=w> </span>and<span class=w> </span>see<span class=w> </span><span class=k>if</span><span class=w> </span>you<span class=w> </span>can<span class=w> </span>locate<span class=w> </span>CUDA<span class=w> </span>libraries.<span class=w> </span>You<span class=w> </span>might<span class=w> </span>need<span class=w> </span>to<span class=w> </span>add<span class=w> </span>them
</span><span id=__span-17-7><a href=#__codelineno-17-7 id=__codelineno-17-7 name=__codelineno-17-7></a><span class=w>        </span>to<span class=w> </span>your<span class=w> </span>LD_LIBRARY_PATH.<span class=w> </span>If<span class=w> </span>you<span class=w> </span>suspect<span class=w> </span>a<span class=w> </span>bug,<span class=w> </span>please<span class=w> </span>take<span class=w> </span>the<span class=w> </span>information<span class=w> </span>from<span class=w> </span>python<span class=w> </span>-m<span class=w> </span>bitsandbytes
</span><span id=__span-17-8><a href=#__codelineno-17-8 id=__codelineno-17-8 name=__codelineno-17-8></a><span class=w>        </span>and<span class=w> </span>open<span class=w> </span>an<span class=w> </span>issue<span class=w> </span>at:<span class=w> </span>https://github.com/TimDettmers/bitsandbytes/issues
</span></code></pre></div><p>上网搜索到<p><a href=https://github.com/TimDettmers/bitsandbytes/issues/175>CUDA Setup failed despite GPU being available. Inspect the CUDA SETUP outputs above to fix your environment! · Issue #175 · TimDettmers/bitsandbytes (github.com)</a><p>注意到 <a href=https://github.com/TimDettmers/bitsandbytes/issues/175#issuecomment-1488003048>Keith-Hon的回答</a>可能可行，并且 <a href=https://github.com/TimDettmers/bitsandbytes/issues/175#issuecomment-1502651860>maximus-sallam也说到他的方法可行</a><div class="admonition quote"><p class=admonition-title>Quote<p>I have fixed it by including the .dll and fixed the file path. It now works on windows 10.<p><a href=https://github.com/Keith-Hon/bitsandbytes-windows.git>https://github.com/Keith-Hon/bitsandbytes-windows.git</a><p>Install the bitsandbytes library by<p>pip install bitsandbytes-windows.<p>Be noted that it may not work directly with transformers library as it references the bitsandbytes package by using 'bitsandbytes' name. &lt;= to avoid this issue, you could directly install from the git repo<p>pip install git+https://github.com/Keith-Hon/bitsandbytes-windows.git</div><blockquote><p>bitsandbytes-windows 的 github 仓库地址<p><a href=https://github.com/Keith-Hon/bitsandbytes-windows>https://github.com/Keith-Hon/bitsandbytes-windows</a></blockquote><p>所以我尝试<div class="language-bash highlight"><pre><span></span><code><span id=__span-18-1><a href=#__codelineno-18-1 id=__codelineno-18-1 name=__codelineno-18-1></a>pip<span class=w> </span>install<span class=w> </span>bitsandbytes-windows
</span></code></pre></div><p>然后发现可行，之前的报错消失了，<p>但随之而来的是，碰到了和上一篇论文一样的问题/报错(连接不了 <code>huggingface.co</code> )<div class="language-bash highlight"><pre><span></span><code><span id=__span-19-1><a href=#__codelineno-19-1 id=__codelineno-19-1 name=__codelineno-19-1></a>requests.exceptions.ProxyError:<span class=w> </span><span class=o>(</span>MaxRetryError<span class=o>(</span><span class=s2>"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /decapoda-research/llama-7b-hf/resolve/main/config.json (Caused by ProxyError('Unable to connect to proxy', SSLError(SSLZeroReturnError(6, 'TLS/SSL connection has been closed (EOF) (_ssl.c:1129)'))))"</span><span class=o>)</span>,<span class=w> </span><span class=s1>'(Request ID: 3eadaf0f-dc33-4690-98b6-d2e5dc10c3ba)'</span><span class=o>)</span>
</span></code></pre></div><hr><h3 id=huggingfaceco>解决 huggingface.co 连接不上问题，成功使用离线模式<a title="Permanent link" class=headerlink href=#huggingfaceco>¶</a></h3><p>搜索相关信息时，发现了一篇文章<p><a href=https://blog.csdn.net/weixin_41862755/article/details/120686319>python 报错 requests.exceptions.ConnectionError: HTTPSConnectionPool(host=‘huggingface.co‘,port=443):M_requests.exceptions.sslerror: httpsconnectionpool(-CSDN博客</a><p>提到了可以将模型下载下来，并提到下载模型可以参阅 <a href=https://blog.csdn.net/weixin_41862755/article/details/120686480>如何从huggingface官网下载模型-CSDN博客</a><p>然后我突然想到了，上一篇论文代码最后的报错信息中，有提到<blockquote><div class="language-bash highlight"><pre><span></span><code><span id=__span-20-1><a href=#__codelineno-20-1 id=__codelineno-20-1 name=__codelineno-20-1></a>Checkout<span class=w> </span>your<span class=w> </span>internet<span class=w> </span>connection<span class=w> </span>or<span class=w> </span>see<span class=w> </span>how<span class=w> </span>to<span class=w> </span>run<span class=w> </span>the<span class=w> </span>library<span class=w> </span><span class=k>in</span><span class=w> </span>offline<span class=w> </span>mode<span class=w> </span>at<span class=w> </span><span class=s1>'https://huggingface.co/docs/transformers/installation#offline-mode'</span>.
</span></code></pre></div></blockquote><p>所以我重新开始查看它的文档并理解应该怎么使用离线模式(之前也看了但是没理解应该怎么使用离线模式)<p><a href=https://huggingface.co/docs/transformers/installation#offline-mode>Offline mode - Installation (huggingface.co) https://huggingface.co/docs/transformers/installation#offline-mode</a><p><mark>由于</mark> csdn 那两篇文章都 <mark>没有明说下载的文件应该放在哪个文件夹</mark>，<mark>所以</mark> 最后我 <mark>判断应该是可以自定义存放的路径</mark> (我一开始以为需要放在指定的路径下)，<strong>于是开始查看应该如何加载自定义的路径</strong><p>然后我先是注意到了官方文档中的<div class="language-python highlight"><pre><span></span><code><span id=__span-21-1><a href=#__codelineno-21-1 id=__codelineno-21-1 name=__codelineno-21-1></a><span class=kn>from</span><span class=w> </span><span class=nn>transformers</span><span class=w> </span><span class=kn>import</span> <span class=n>T5Model</span>
</span><span id=__span-21-2><a href=#__codelineno-21-2 id=__codelineno-21-2 name=__codelineno-21-2></a>
</span><span id=__span-21-3><a href=#__codelineno-21-3 id=__codelineno-21-3 name=__codelineno-21-3></a><span class=n>model</span> <span class=o>=</span> <span class=n>T5Model</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=s2>"./path/to/local/directory"</span><span class=p>,</span> <span class=n>local_files_only</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></code></pre></div><p>这里我认为是开始加载了模型，于是我在 <code>rec.py</code> 中查找对应的代码，发现 104 行有加载模型的代码<div class="language-python highlight"><pre><span></span><code><span id=__span-22-1><a href=#__codelineno-22-1 id=__codelineno-22-1 name=__codelineno-22-1></a>    <span class=n>model</span> <span class=o>=</span> <span class=n>LlamaForCausalLM</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span>
</span><span id=__span-22-2><a href=#__codelineno-22-2 id=__codelineno-22-2 name=__codelineno-22-2></a>        <span class=n>base_model</span><span class=p>,</span>
</span><span id=__span-22-3><a href=#__codelineno-22-3 id=__codelineno-22-3 name=__codelineno-22-3></a>        <span class=n>load_in_8bit</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span><span id=__span-22-4><a href=#__codelineno-22-4 id=__codelineno-22-4 name=__codelineno-22-4></a>        <span class=n>torch_dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float16</span><span class=p>,</span>
</span><span id=__span-22-5><a href=#__codelineno-22-5 id=__codelineno-22-5 name=__codelineno-22-5></a>        <span class=n>device_map</span><span class=o>=</span><span class=n>device_map</span><span class=p>,</span>
</span><span id=__span-22-6><a href=#__codelineno-22-6 id=__codelineno-22-6 name=__codelineno-22-6></a>    <span class=p>)</span>
</span></code></pre></div><p>然后 <span class=keys><kbd class=key-control>Ctrl</kbd></span> + 点击 <code>base_model</code> 查看具体它是什么，然后跳转到第 28 行<div class="language-python highlight"><pre><span></span><code><span id=__span-23-1><a href=#__codelineno-23-1 id=__codelineno-23-1 name=__codelineno-23-1></a><span class=k>def</span><span class=w> </span><span class=nf>train</span><span class=p>(</span>
</span><span id=__span-23-2><a href=#__codelineno-23-2 id=__codelineno-23-2 name=__codelineno-23-2></a>    <span class=c1># model/data params</span>
</span><span id=__span-23-3><a href=#__codelineno-23-3 id=__codelineno-23-3 name=__codelineno-23-3></a>    <span class=n>base_model</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>""</span><span class=p>,</span>  <span class=c1># the only required argument</span>
</span><span id=__span-23-4><a href=#__codelineno-23-4 id=__codelineno-23-4 name=__codelineno-23-4></a>    <span class=n>data_path</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>"yahma/alpaca-cleaned"</span><span class=p>,</span>
</span><span id=__span-23-5><a href=#__codelineno-23-5 id=__codelineno-23-5 name=__codelineno-23-5></a>    <span class=n>output_dir</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>"/common/users/jj635/llama/mycheckpoint/"</span><span class=p>,</span>
</span><span id=__span-23-6><a href=#__codelineno-23-6 id=__codelineno-23-6 name=__codelineno-23-6></a>    <span class=c1># training hyperparams</span>
</span><span id=__span-23-7><a href=#__codelineno-23-7 id=__codelineno-23-7 name=__codelineno-23-7></a>    <span class=n>batch_size</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>128</span><span class=p>,</span><span class=c1>#used to be 128</span>
</span><span id=__span-23-8><a href=#__codelineno-23-8 id=__codelineno-23-8 name=__codelineno-23-8></a>    <span class=n>micro_batch_size</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>4</span><span class=p>,</span>
</span><span id=__span-23-9><a href=#__codelineno-23-9 id=__codelineno-23-9 name=__codelineno-23-9></a>    <span class=n>num_epochs</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>3</span><span class=p>,</span>
</span><span id=__span-23-10><a href=#__codelineno-23-10 id=__codelineno-23-10 name=__codelineno-23-10></a>    <span class=o>...</span>
</span></code></pre></div><p>然后想到了命令行输入的命令(也是感觉到跟之前使用 yolov7 时，<em>命令行命令和代码中的对应关系</em> 有点像)<div class="language-bash highlight"><pre><span></span><code><span id=__span-24-1><a href=#__codelineno-24-1 id=__codelineno-24-1 name=__codelineno-24-1></a>python<span class=w> </span>rec.py<span class=w> </span><span class=se>\</span>
</span><span id=__span-24-2><a href=#__codelineno-24-2 id=__codelineno-24-2 name=__codelineno-24-2></a><span class=w>    </span>--base_model<span class=w> </span><span class=s1>'decapoda-research/llama-7b-hf'</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-24-3><a href=#__codelineno-24-3 id=__codelineno-24-3 name=__codelineno-24-3></a><span class=w>    </span>--data_path<span class=w> </span><span class=s1>'./moives'</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-24-4><a href=#__codelineno-24-4 id=__codelineno-24-4 name=__codelineno-24-4></a><span class=w>    </span>--output_dir<span class=w> </span><span class=s1>'./checkpoint'</span>
</span></code></pre></div><p>然后再对比官方文档中的，离线模式的命令行命令<div class="language-bash highlight"><pre><span></span><code><span id=__span-25-1><a href=#__codelineno-25-1 id=__codelineno-25-1 name=__codelineno-25-1></a><span class=nv>HF_DATASETS_OFFLINE</span><span class=o>=</span><span class=m>1</span><span class=w> </span><span class=nv>TRANSFORMERS_OFFLINE</span><span class=o>=</span><span class=m>1</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-25-2><a href=#__codelineno-25-2 id=__codelineno-25-2 name=__codelineno-25-2></a>python<span class=w> </span>examples/pytorch/translation/run_translation.py<span class=w> </span>--model_name_or_path<span class=w> </span>t5-small<span class=w> </span>--dataset_name<span class=w> </span>wmt16<span class=w> </span>--dataset_config<span class=w> </span>ro-en<span class=w> </span>...
</span></code></pre></div><p><mark>所以得到一个可能的解决方法</mark>，即先将<p>于是按照 <a href=https://blog.csdn.net/weixin_41862755/article/details/120686480>如何从huggingface官网下载模型-CSDN博客</a> 中写的，在 <a href=https://huggingface.co/models>Models - Hugging Face https://huggingface.co/models</a> 中找到/查询到对应的模型库<ul><li><p>根据之前的报错信息</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-26-1><a href=#__codelineno-26-1 id=__codelineno-26-1 name=__codelineno-26-1></a>...<span class=w> </span>Max<span class=w> </span>retries<span class=w> </span>exceeded<span class=w> </span>with<span class=w> </span>url:<span class=w> </span>/decapoda-research/llama-7b-hf/resolve/main/config.json<span class=w> </span>...
</span></code></pre></div><li><p>或者根据使用的命令中的</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-27-1><a href=#__codelineno-27-1 id=__codelineno-27-1 name=__codelineno-27-1></a><span class=w>    </span>--base_model<span class=w> </span><span class=s1>'decapoda-research/llama-7b-hf'</span><span class=w> </span><span class=se>\</span>
</span></code></pre></div></ul><p>可以找到相应的网址<p><a href=https://huggingface.co/decapoda-research/llama-7b-hf>decapoda-research/llama-7b-hf · Hugging Face</a><p>然后点击 <code>File and versions</code> ，就可以在这里下载<p><a href=https://huggingface.co/decapoda-research/llama-7b-hf/tree/main>decapoda-research/llama-7b-hf at main (huggingface.co)</a><p>最后对 <code>rec.py</code> 中进行相应的修改，之前的报错消失<blockquote><p>但是出现了和之前(最开始时)一样的报错信息🙃🙄(怎么兜兜转转回到原地)<div class="language-bash highlight"><pre><span></span><code><span id=__span-28-1><a href=#__codelineno-28-1 id=__codelineno-28-1 name=__codelineno-28-1></a>ValueError:u
</span><span id=__span-28-2><a href=#__codelineno-28-2 id=__codelineno-28-2 name=__codelineno-28-2></a><span class=w>                        </span>Some<span class=w> </span>modules<span class=w> </span>are<span class=w> </span>dispatched<span class=w> </span>on<span class=w> </span>the<span class=w> </span>CPU<span class=w> </span>or<span class=w> </span>the<span class=w> </span>disk.<span class=w> </span>Make<span class=w> </span>sure<span class=w> </span>you<span class=w> </span>have<span class=w> </span>enough<span class=w> </span>GPU<span class=w> </span>RAM<span class=w> </span>to<span class=w> </span>fit
</span><span id=__span-28-3><a href=#__codelineno-28-3 id=__codelineno-28-3 name=__codelineno-28-3></a><span class=w>                        </span>the<span class=w> </span>quantized<span class=w> </span>model.<span class=w> </span>If<span class=w> </span>you<span class=w> </span>want<span class=w> </span>to<span class=w> </span>dispatch<span class=w> </span>the<span class=w> </span>model<span class=w> </span>on<span class=w> </span>the<span class=w> </span>CPU<span class=w> </span>or<span class=w> </span>the<span class=w> </span>disk<span class=w> </span><span class=k>while</span><span class=w> </span>keeping
</span><span id=__span-28-4><a href=#__codelineno-28-4 id=__codelineno-28-4 name=__codelineno-28-4></a><span class=w>                        </span>these<span class=w> </span>modules<span class=w> </span><span class=k>in</span><span class=w> </span><span class=m>32</span>-bit,<span class=w> </span>you<span class=w> </span>need<span class=w> </span>to<span class=w> </span><span class=nb>set</span><span class=w> </span><span class=sb>`</span><span class=nv>load_in_8bit_fp32_cpu_offload</span><span class=o>=</span>True<span class=sb>`</span><span class=w> </span>and<span class=w> </span>pass<span class=w> </span>a<span class=w> </span>custom
</span><span id=__span-28-5><a href=#__codelineno-28-5 id=__codelineno-28-5 name=__codelineno-28-5></a><span class=w>                        </span><span class=sb>`</span>device_map<span class=sb>`</span><span class=w> </span>to<span class=w> </span><span class=sb>`</span>from_pretrained<span class=sb>`</span>.<span class=w> </span>Check
</span><span id=__span-28-6><a href=#__codelineno-28-6 id=__codelineno-28-6 name=__codelineno-28-6></a><span class=w>                        </span>https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu
</span><span id=__span-28-7><a href=#__codelineno-28-7 id=__codelineno-28-7 name=__codelineno-28-7></a><span class=w>                        </span><span class=k>for</span><span class=w> </span>more<span class=w> </span>details.
</span></code></pre></div></blockquote><hr><p>粗略尝试了<p><a href=https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu>Quantize 🤗 Transformers models (huggingface.co) https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu</a><p>上的方法，我将代码修改成<div class="language-python highlight"><pre><span></span><code><span id=__span-29-1><a href=#__codelineno-29-1 id=__codelineno-29-1 name=__codelineno-29-1></a><span class=n>model</span> <span class=o>=</span> <span class=n>LlamaForCausalLM</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span>
</span><span id=__span-29-2><a href=#__codelineno-29-2 id=__codelineno-29-2 name=__codelineno-29-2></a>        <span class=c1># base_model,</span>
</span><span id=__span-29-3><a href=#__codelineno-29-3 id=__codelineno-29-3 name=__codelineno-29-3></a>        <span class=s2>"../llama-7b-hf"</span><span class=p>,</span>
</span><span id=__span-29-4><a href=#__codelineno-29-4 id=__codelineno-29-4 name=__codelineno-29-4></a>        <span class=n>load_in_8bit</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span><span id=__span-29-5><a href=#__codelineno-29-5 id=__codelineno-29-5 name=__codelineno-29-5></a>        <span class=n>torch_dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float16</span><span class=p>,</span>
</span><span id=__span-29-6><a href=#__codelineno-29-6 id=__codelineno-29-6 name=__codelineno-29-6></a>        <span class=c1># device_map=device_map,</span>
</span><span id=__span-29-7><a href=#__codelineno-29-7 id=__codelineno-29-7 name=__codelineno-29-7></a>
</span><span id=__span-29-8><a href=#__codelineno-29-8 id=__codelineno-29-8 name=__codelineno-29-8></a>        <span class=n>local_files_only</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span><span id=__span-29-9><a href=#__codelineno-29-9 id=__codelineno-29-9 name=__codelineno-29-9></a>        <span class=n>device_map</span><span class=o>=</span><span class=p>{</span>
</span><span id=__span-29-10><a href=#__codelineno-29-10 id=__codelineno-29-10 name=__codelineno-29-10></a>            <span class=s2>"transformer.word_embeddings"</span><span class=p>:</span> <span class=mi>0</span><span class=p>,</span>
</span><span id=__span-29-11><a href=#__codelineno-29-11 id=__codelineno-29-11 name=__codelineno-29-11></a>            <span class=s2>"transformer.word_embeddings_layernorm"</span><span class=p>:</span> <span class=mi>0</span><span class=p>,</span>
</span><span id=__span-29-12><a href=#__codelineno-29-12 id=__codelineno-29-12 name=__codelineno-29-12></a>            <span class=s2>"lm_head"</span><span class=p>:</span> <span class=s2>"cpu"</span><span class=p>,</span>
</span><span id=__span-29-13><a href=#__codelineno-29-13 id=__codelineno-29-13 name=__codelineno-29-13></a>            <span class=s2>"transformer.h"</span><span class=p>:</span> <span class=mi>0</span><span class=p>,</span>
</span><span id=__span-29-14><a href=#__codelineno-29-14 id=__codelineno-29-14 name=__codelineno-29-14></a>            <span class=s2>"transformer.ln_f"</span><span class=p>:</span> <span class=mi>0</span><span class=p>,</span>
</span><span id=__span-29-15><a href=#__codelineno-29-15 id=__codelineno-29-15 name=__codelineno-29-15></a>        <span class=p>},</span>
</span><span id=__span-29-16><a href=#__codelineno-29-16 id=__codelineno-29-16 name=__codelineno-29-16></a>        <span class=n>quantization_config</span><span class=o>=</span><span class=n>BitsAndBytesConfig</span><span class=p>(</span><span class=n>llm_int8_enable_fp32_cpu_offload</span><span class=o>=</span><span class=kc>True</span><span class=p>),</span>
</span><span id=__span-29-17><a href=#__codelineno-29-17 id=__codelineno-29-17 name=__codelineno-29-17></a>    <span class=p>)</span>
</span></code></pre></div><p>但最后显示<div class="language-bash highlight"><pre><span></span><code><span id=__span-30-1><a href=#__codelineno-30-1 id=__codelineno-30-1 name=__codelineno-30-1></a><span class=o>===================================</span>BUG<span class=w> </span><span class=nv>REPORT</span><span class=o>===================================</span>
</span><span id=__span-30-2><a href=#__codelineno-30-2 id=__codelineno-30-2 name=__codelineno-30-2></a>Welcome<span class=w> </span>to<span class=w> </span>bitsandbytes.<span class=w> </span>For<span class=w> </span>bug<span class=w> </span>reports,<span class=w> </span>please<span class=w> </span>submit<span class=w> </span>your<span class=w> </span>error<span class=w> </span>trace<span class=w> </span>to:<span class=w> </span>https://github.com/TimDettmers/bitsandbytes/issues
</span><span id=__span-30-3><a href=#__codelineno-30-3 id=__codelineno-30-3 name=__codelineno-30-3></a><span class=o>================================================================================</span>
</span><span id=__span-30-4><a href=#__codelineno-30-4 id=__codelineno-30-4 name=__codelineno-30-4></a>binary_path:<span class=w> </span>E:<span class=se>\P</span>rograms<span class=se>\A</span>naconda3<span class=se>\e</span>nvs<span class=se>\g</span>enrec<span class=se>\l</span>ib<span class=se>\s</span>ite-packages<span class=se>\b</span>itsandbytes<span class=se>\c</span>uda_setup<span class=se>\l</span>ibbitsandbytes_cuda116.dll
</span><span id=__span-30-5><a href=#__codelineno-30-5 id=__codelineno-30-5 name=__codelineno-30-5></a>CUDA<span class=w> </span>SETUP:<span class=w> </span>Loading<span class=w> </span>binary<span class=w> </span>E:<span class=se>\P</span>rograms<span class=se>\A</span>naconda3<span class=se>\e</span>nvs<span class=se>\g</span>enrec<span class=se>\l</span>ib<span class=se>\s</span>ite-packages<span class=se>\b</span>itsandbytes<span class=se>\c</span>uda_setup<span class=se>\l</span>ibbitsandbytes_cuda116.dll...
</span><span id=__span-30-6><a href=#__codelineno-30-6 id=__codelineno-30-6 name=__codelineno-30-6></a>Training<span class=w> </span>Alpaca-LoRA<span class=w> </span>model<span class=w> </span>with<span class=w> </span>params:
</span><span id=__span-30-7><a href=#__codelineno-30-7 id=__codelineno-30-7 name=__codelineno-30-7></a>base_model:<span class=w> </span>decapoda-research/llama-7b-hf
</span><span id=__span-30-8><a href=#__codelineno-30-8 id=__codelineno-30-8 name=__codelineno-30-8></a>data_path:<span class=w> </span>./moives
</span><span id=__span-30-9><a href=#__codelineno-30-9 id=__codelineno-30-9 name=__codelineno-30-9></a>output_dir:<span class=w> </span>./checkpoint
</span><span id=__span-30-10><a href=#__codelineno-30-10 id=__codelineno-30-10 name=__codelineno-30-10></a>batch_size:<span class=w> </span><span class=m>128</span>
</span><span id=__span-30-11><a href=#__codelineno-30-11 id=__codelineno-30-11 name=__codelineno-30-11></a>micro_batch_size:<span class=w> </span><span class=m>4</span>
</span><span id=__span-30-12><a href=#__codelineno-30-12 id=__codelineno-30-12 name=__codelineno-30-12></a>num_epochs:<span class=w> </span><span class=m>3</span>
</span><span id=__span-30-13><a href=#__codelineno-30-13 id=__codelineno-30-13 name=__codelineno-30-13></a>learning_rate:<span class=w> </span><span class=m>0</span>.0003
</span><span id=__span-30-14><a href=#__codelineno-30-14 id=__codelineno-30-14 name=__codelineno-30-14></a>cutoff_len:<span class=w> </span><span class=m>256</span>
</span><span id=__span-30-15><a href=#__codelineno-30-15 id=__codelineno-30-15 name=__codelineno-30-15></a>val_set_size:<span class=w> </span><span class=m>0</span>
</span><span id=__span-30-16><a href=#__codelineno-30-16 id=__codelineno-30-16 name=__codelineno-30-16></a>lora_r:<span class=w> </span><span class=m>8</span>
</span><span id=__span-30-17><a href=#__codelineno-30-17 id=__codelineno-30-17 name=__codelineno-30-17></a>lora_alpha:<span class=w> </span><span class=m>16</span>
</span><span id=__span-30-18><a href=#__codelineno-30-18 id=__codelineno-30-18 name=__codelineno-30-18></a>lora_dropout:<span class=w> </span><span class=m>0</span>.05
</span><span id=__span-30-19><a href=#__codelineno-30-19 id=__codelineno-30-19 name=__codelineno-30-19></a>lora_target_modules:<span class=w> </span><span class=o>[</span><span class=s1>'q_proj'</span>,<span class=w> </span><span class=s1>'v_proj'</span><span class=o>]</span>
</span><span id=__span-30-20><a href=#__codelineno-30-20 id=__codelineno-30-20 name=__codelineno-30-20></a>train_on_inputs:<span class=w> </span>True
</span><span id=__span-30-21><a href=#__codelineno-30-21 id=__codelineno-30-21 name=__codelineno-30-21></a>group_by_length:<span class=w> </span>False
</span><span id=__span-30-22><a href=#__codelineno-30-22 id=__codelineno-30-22 name=__codelineno-30-22></a>wandb_project:
</span><span id=__span-30-23><a href=#__codelineno-30-23 id=__codelineno-30-23 name=__codelineno-30-23></a>wandb_run_name:
</span><span id=__span-30-24><a href=#__codelineno-30-24 id=__codelineno-30-24 name=__codelineno-30-24></a>wandb_watch:
</span><span id=__span-30-25><a href=#__codelineno-30-25 id=__codelineno-30-25 name=__codelineno-30-25></a>wandb_log_model:
</span><span id=__span-30-26><a href=#__codelineno-30-26 id=__codelineno-30-26 name=__codelineno-30-26></a>resume_from_checkpoint:<span class=w> </span>None
</span><span id=__span-30-27><a href=#__codelineno-30-27 id=__codelineno-30-27 name=__codelineno-30-27></a>
</span><span id=__span-30-28><a href=#__codelineno-30-28 id=__codelineno-30-28 name=__codelineno-30-28></a>Loading<span class=w> </span>checkpoint<span class=w> </span>shards:<span class=w>   </span><span class=m>0</span>%<span class=p>|</span><span class=w>                                                                </span><span class=p>|</span><span class=w> </span><span class=m>0</span>/33<span class=w> </span><span class=o>[</span><span class=m>00</span>:00&lt;?,<span class=w> </span>?it/s<span class=o>]</span>
</span><span id=__span-30-29><a href=#__codelineno-30-29 id=__codelineno-30-29 name=__codelineno-30-29></a>Traceback<span class=w> </span><span class=o>(</span>most<span class=w> </span>recent<span class=w> </span>call<span class=w> </span>last<span class=o>)</span>:
</span><span id=__span-30-30><a href=#__codelineno-30-30 id=__codelineno-30-30 name=__codelineno-30-30></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Github\code_reproduction\GenRec\rec.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>302</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>&lt;module>
</span><span id=__span-30-31><a href=#__codelineno-30-31 id=__codelineno-30-31 name=__codelineno-30-31></a><span class=w>    </span>fire.Fire<span class=o>(</span>train<span class=o>)</span>
</span><span id=__span-30-32><a href=#__codelineno-30-32 id=__codelineno-30-32 name=__codelineno-30-32></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\genrec\lib\site-packages\fire\core.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>141</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>Fire
</span><span id=__span-30-33><a href=#__codelineno-30-33 id=__codelineno-30-33 name=__codelineno-30-33></a><span class=w>    </span><span class=nv>component_trace</span><span class=w> </span><span class=o>=</span><span class=w> </span>_Fire<span class=o>(</span>component,<span class=w> </span>args,<span class=w> </span>parsed_flag_args,<span class=w> </span>context,<span class=w> </span>name<span class=o>)</span>
</span><span id=__span-30-34><a href=#__codelineno-30-34 id=__codelineno-30-34 name=__codelineno-30-34></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\genrec\lib\site-packages\fire\core.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>475</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>_Fire
</span><span id=__span-30-35><a href=#__codelineno-30-35 id=__codelineno-30-35 name=__codelineno-30-35></a><span class=w>    </span>component,<span class=w> </span><span class=nv>remaining_args</span><span class=w> </span><span class=o>=</span><span class=w> </span>_CallAndUpdateTrace<span class=o>(</span>
</span><span id=__span-30-36><a href=#__codelineno-30-36 id=__codelineno-30-36 name=__codelineno-30-36></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\genrec\lib\site-packages\fire\core.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>691</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>_CallAndUpdateTrace
</span><span id=__span-30-37><a href=#__codelineno-30-37 id=__codelineno-30-37 name=__codelineno-30-37></a><span class=w>    </span><span class=nv>component</span><span class=w> </span><span class=o>=</span><span class=w> </span>fn<span class=o>(</span>*varargs,<span class=w> </span>**kwargs<span class=o>)</span>
</span><span id=__span-30-38><a href=#__codelineno-30-38 id=__codelineno-30-38 name=__codelineno-30-38></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Github\code_reproduction\GenRec\rec.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>106</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>train
</span><span id=__span-30-39><a href=#__codelineno-30-39 id=__codelineno-30-39 name=__codelineno-30-39></a><span class=w>    </span><span class=nv>model</span><span class=w> </span><span class=o>=</span><span class=w> </span>LlamaForCausalLM.from_pretrained<span class=o>(</span>
</span><span id=__span-30-40><a href=#__codelineno-30-40 id=__codelineno-30-40 name=__codelineno-30-40></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\genrec\lib\site-packages\transformers\modeling_utils.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>2881</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>from_pretrained
</span><span id=__span-30-41><a href=#__codelineno-30-41 id=__codelineno-30-41 name=__codelineno-30-41></a><span class=w>    </span><span class=o>)</span><span class=w> </span><span class=o>=</span><span class=w> </span>cls._load_pretrained_model<span class=o>(</span>
</span><span id=__span-30-42><a href=#__codelineno-30-42 id=__codelineno-30-42 name=__codelineno-30-42></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\genrec\lib\site-packages\transformers\modeling_utils.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>3228</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>_load_pretrained_model
</span><span id=__span-30-43><a href=#__codelineno-30-43 id=__codelineno-30-43 name=__codelineno-30-43></a><span class=w>    </span>new_error_msgs,<span class=w> </span>offload_index,<span class=w> </span><span class=nv>state_dict_index</span><span class=w> </span><span class=o>=</span><span class=w> </span>_load_state_dict_into_meta_model<span class=o>(</span>
</span><span id=__span-30-44><a href=#__codelineno-30-44 id=__codelineno-30-44 name=__codelineno-30-44></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\genrec\lib\site-packages\transformers\modeling_utils.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>710</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>_load_state_dict_into_meta_model
</span><span id=__span-30-45><a href=#__codelineno-30-45 id=__codelineno-30-45 name=__codelineno-30-45></a><span class=w>    </span>raise<span class=w> </span>ValueError<span class=o>(</span>f<span class=s2>"{param_name} doesn't have any device set."</span><span class=o>)</span>
</span><span id=__span-30-46><a href=#__codelineno-30-46 id=__codelineno-30-46 name=__codelineno-30-46></a>ValueError:<span class=w> </span>model.layers.0.self_attn.q_proj.weight<span class=w> </span>doesn<span class=err>'</span>t<span class=w> </span>have<span class=w> </span>any<span class=w> </span>device<span class=w> </span>set.
</span></code></pre></div><hr><p>看到了这个问题<p><a href=https://huggingface.co/google/flan-ul2/discussions/8>google/flan-ul2 · ValueError: Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM (huggingface.co)</a><p>根据其中<a href=https://huggingface.co/google/flan-ul2/discussions/8#6436f03af8962b4332ba2644>ybelkaba 的回答</a>所提到的，我猜这个报错应该由于cpu和gpu内存不够大<hr><h2 id=openp5_1>OpenP5 (第二次尝试)<a title="Permanent link" class=headerlink href=#openp5_1>¶</a></h2><p>由于 GenRec 的代码遇到的问题暂时不知道如何解决，并且由于解决了 huggingface.co 的离线使用问题，所以打算再次尝试运行 OpenP5<p>首先是下载模型，然后修改相应的代码<p>我在 <code>./src/main.py</code> 第 88 行处新增一行 <code>args.backbone = "../../" + args.backbone</code> ：<div class="language-python highlight"><pre><span></span><code><span id=__span-31-1><a href=#__codelineno-31-1 id=__codelineno-31-1 name=__codelineno-31-1></a>    <span class=o>...</span>
</span><span id=__span-31-2><a href=#__codelineno-31-2 id=__codelineno-31-2 name=__codelineno-31-2></a>    <span class=n>args</span><span class=o>.</span><span class=n>rank</span> <span class=o>=</span> <span class=mi>0</span>
</span><span id=__span-31-3><a href=#__codelineno-31-3 id=__codelineno-31-3 name=__codelineno-31-3></a>
</span><span id=__span-31-4><a href=#__codelineno-31-4 id=__codelineno-31-4 name=__codelineno-31-4></a>    <span class=n>device</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s2>"cuda"</span><span class=p>,</span> <span class=nb>int</span><span class=p>(</span><span class=n>args</span><span class=o>.</span><span class=n>gpu</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s1>','</span><span class=p>)[</span><span class=mi>0</span><span class=p>]))</span>
</span><span id=__span-31-5><a href=#__codelineno-31-5 id=__codelineno-31-5 name=__codelineno-31-5></a>    <span class=c1># offline set</span>
</span><span id=__span-31-6><a href=#__codelineno-31-6 id=__codelineno-31-6 name=__codelineno-31-6></a>    <span class=n>args</span><span class=o>.</span><span class=n>backbone</span> <span class=o>=</span> <span class=s2>"../../"</span> <span class=o>+</span> <span class=n>args</span><span class=o>.</span><span class=n>backbone</span>
</span><span id=__span-31-7><a href=#__codelineno-31-7 id=__codelineno-31-7 name=__codelineno-31-7></a>    <span class=o>...</span>
</span></code></pre></div><p>并且把每个 <code>.from_pretrained()</code> 中都加上了 <code>local_files_only=True</code> ，并且运行<div class="language-bash highlight"><pre><span></span><code><span id=__span-32-1><a href=#__codelineno-32-1 id=__codelineno-32-1 name=__codelineno-32-1></a><span class=nv>HF_DATASETS_OFFLINE</span><span class=o>=</span><span class=m>1</span><span class=w> </span><span class=nv>TRANSFORMERS_OFFLINE</span><span class=o>=</span><span class=m>1</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-32-2><a href=#__codelineno-32-2 id=__codelineno-32-2 name=__codelineno-32-2></a>sh<span class=w> </span>ML1M_random.sh
</span></code></pre></div><p>运行时，之前的报错消失了，变成了<div class="language-bash highlight"><pre><span></span><code><span id=__span-33-1><a href=#__codelineno-33-1 id=__codelineno-33-1 name=__codelineno-33-1></a>Traceback<span class=w> </span><span class=o>(</span>most<span class=w> </span>recent<span class=w> </span>call<span class=w> </span>last<span class=o>)</span>:
</span><span id=__span-33-2><a href=#__codelineno-33-2 id=__codelineno-33-2 name=__codelineno-33-2></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Github\code_reproduction\OpenP5-old_version\src\main.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>241</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>&lt;module>
</span><span id=__span-33-3><a href=#__codelineno-33-3 id=__codelineno-33-3 name=__codelineno-33-3></a><span class=w>    </span>single_main<span class=o>()</span>
</span><span id=__span-33-4><a href=#__codelineno-33-4 id=__codelineno-33-4 name=__codelineno-33-4></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Github\code_reproduction\OpenP5-old_version\src\main.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>98</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>single_main
</span><span id=__span-33-5><a href=#__codelineno-33-5 id=__codelineno-33-5 name=__codelineno-33-5></a><span class=w>    </span>TrainSet,<span class=w> </span><span class=nv>ValidSet</span><span class=w> </span><span class=o>=</span><span class=w> </span>get_dataset<span class=o>(</span>args<span class=o>)</span>
</span><span id=__span-33-6><a href=#__codelineno-33-6 id=__codelineno-33-6 name=__codelineno-33-6></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Github\code_reproduction\OpenP5-old_version\src\main.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>33</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>get_dataset
</span><span id=__span-33-7><a href=#__codelineno-33-7 id=__codelineno-33-7 name=__codelineno-33-7></a><span class=w>    </span><span class=nv>TrainDataset</span><span class=w> </span><span class=o>=</span><span class=w> </span>MultiTaskDataset<span class=o>(</span>args,<span class=w> </span>data,<span class=w> </span><span class=s1>'train'</span><span class=o>)</span>
</span><span id=__span-33-8><a href=#__codelineno-33-8 id=__codelineno-33-8 name=__codelineno-33-8></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Github\code_reproduction\OpenP5-old_version\src\data\MultiTaskDataset.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>110</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>__init__
</span><span id=__span-33-9><a href=#__codelineno-33-9 id=__codelineno-33-9 name=__codelineno-33-9></a><span class=w>    </span>dist.barrier<span class=o>()</span>
</span><span id=__span-33-10><a href=#__codelineno-33-10 id=__codelineno-33-10 name=__codelineno-33-10></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\openp5\lib\site-packages\torch\distributed\distributed_c10d.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>2419</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>barrier
</span><span id=__span-33-11><a href=#__codelineno-33-11 id=__codelineno-33-11 name=__codelineno-33-11></a><span class=w>    </span><span class=nv>default_pg</span><span class=w> </span><span class=o>=</span><span class=w> </span>_get_default_group<span class=o>()</span>
</span><span id=__span-33-12><a href=#__codelineno-33-12 id=__codelineno-33-12 name=__codelineno-33-12></a><span class=w>  </span>File<span class=w> </span><span class=s2>"E:\Programs\Anaconda3\envs\openp5\lib\site-packages\torch\distributed\distributed_c10d.py"</span>,<span class=w> </span>line<span class=w> </span><span class=m>347</span>,<span class=w> </span><span class=k>in</span><span class=w> </span>_get_default_group
</span><span id=__span-33-13><a href=#__codelineno-33-13 id=__codelineno-33-13 name=__codelineno-33-13></a><span class=w>    </span>raise<span class=w> </span>RuntimeError<span class=o>(</span><span class=s2>"Default process group has not been initialized, "</span>
</span><span id=__span-33-14><a href=#__codelineno-33-14 id=__codelineno-33-14 name=__codelineno-33-14></a>RuntimeError:<span class=w> </span>Default<span class=w> </span>process<span class=w> </span>group<span class=w> </span>has<span class=w> </span>not<span class=w> </span>been<span class=w> </span>initialized,<span class=w> </span>please<span class=w> </span>make<span class=w> </span>sure<span class=w> </span>to<span class=w> </span>call<span class=w> </span>init_process_group.
</span></code></pre></div><hr><div class=md-source-file><small> 最后更新: <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-timeago"><span class=timeago datetime=2023-10-08T07:22:37+00:00 locale=en></span></span><span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_date">2023-10-08</span> <br> 创建日期: <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-timeago"><span class=timeago datetime=2023-10-04T05:24:18+00:00 locale=en></span></span><span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_date">2023-10-04</span> </small></div><h2 id=__comments>评论</h2><script async crossorigin data-category=Announcements data-category-id=DIC_kwDOKTCz0s4CZ2M5 data-emit-metadata=1 data-input-position=top data-lang=zh-CN data-loading=lazy data-mapping=pathname data-reactions-enabled=1 data-repo=RonaldLN/MyPamphlet-Blog data-repo-id=R_kgDOKTCz0g data-strict=0 data-theme=https://cdn.jsdelivr.net/gh/RonaldLN/MyPamphlet-Blog@main/docs/stylesheets/giscus_sunset_glow.css src=https://giscus.app/client.js></script><script>var giscus = document.querySelector("script[src*=giscus]")

    // Set palette on initial load
    var palette = __md_get("__palette")
    if (palette && typeof palette.color === "object") {
      var theme = palette.color.scheme === "sunset-glow-dark"
        ? "https://cdn.jsdelivr.net/gh/RonaldLN/MyPamphlet-Blog@main/docs/stylesheets/giscus_sunset_glow_dark.css"
        : "https://cdn.jsdelivr.net/gh/RonaldLN/MyPamphlet-Blog@main/docs/stylesheets/giscus_sunset_glow.css"

      // Instruct Giscus to set theme
      giscus.setAttribute("data-theme", theme) 
    }

    // Register event handlers after documented loaded
    document.addEventListener("DOMContentLoaded", function() {
      var ref = document.querySelector("[data-md-component=palette]")
      ref.addEventListener("change", function() {
        var palette = __md_get("__palette")
        if (palette && typeof palette.color === "object") {
          var theme = palette.color.scheme === "sunset-glow-dark"
            ? "https://cdn.jsdelivr.net/gh/RonaldLN/MyPamphlet-Blog@main/docs/stylesheets/giscus_sunset_glow_dark.css"
            : "https://cdn.jsdelivr.net/gh/RonaldLN/MyPamphlet-Blog@main/docs/stylesheets/giscus_sunset_glow.css"

          // Instruct Giscus to change theme
          var frame = document.querySelector(".giscus-frame")
          frame.contentWindow.postMessage(
            { giscus: { setConfig: { theme } } },
            "https://giscus.app"
          )
        }
      })
    })</script></article></div></div><button class="md-top md-icon" data-md-component=top hidden type=button><svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg> 回到页面顶部</button></main><footer class=md-footer><nav class="md-footer__inner md-grid" aria-label=页脚><a aria-label="上一页: 成功修改视频的exif信息(QuickTime创建时间)" class="md-footer__link md-footer__link--prev" href=../03/exifquicktime/> <div class="md-footer__button md-icon"><svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg></div> <div class=md-footer__title><span class=md-footer__direction> 上一页 </span><div class=md-ellipsis>成功修改视频的exif信息(QuickTime创建时间)</div></div> </a><a aria-label="下一页: 阅读第一篇论文 Neural Collaborative Filtering" class="md-footer__link md-footer__link--next" href=../08/neural-collaborative-filteringhttpspaperswithcodecompaperneural-collaborative-filtering/> <div class=md-footer__title><span class=md-footer__direction> 下一页 </span><div class=md-ellipsis>阅读第一篇论文 Neural Collaborative Filtering</div></div> <div class="md-footer__button md-icon"><svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg></div> </a></nav><div class="md-footer-meta md-typeset"><div class="md-footer-meta__inner md-grid"><div class=md-copyright><div class=md-copyright__highlight>Copyright © 2023 - 2025 Ronald Luo</div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ rel=noopener target=_blank> Material for MkDocs </a></div></div></div></footer></div><div class=md-dialog data-md-component=dialog><div class="md-dialog__inner md-typeset"></div></div><div class=md-progress data-md-component=progress role=progressbar></div><script id=__config type=application/json>{"base": "../../..", "features": ["navigation.expand", "toc.follow", "navigation.top", "search.suggest", "navigation.footer", "navigation.tabs", "navigation.tracking", "navigation.instant", "navigation.instant.progress", "content.code.copy", "search.suggest", "search.highlight", "search.share"], "search": "../../../assets/javascripts/workers/search.f886a092.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script><script src=../../../assets/javascripts/bundle.aecac24b.min.js></script><script src=../../../js/timeago.min.js></script><script src=../../../js/timeago_mkdocs_material.js></script><script src=../../../javascripts/katex.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/katex.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/contrib/auto-render.min.js></script><script>document$.subscribe(() => {const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});})</script>